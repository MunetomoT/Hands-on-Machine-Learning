{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "\n",
    "def reset_graph(seed = 42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 8a) Build a DNN with five hidden layers of 100 neurons with He initialization and the ELU activation function\n",
    "\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "def dnn(inputs, n_hidden_layers = 5, n_neurons = 100, name = None, activation = tf.nn.elu, initializer = he_init):\n",
    "    with tf.name_scope(name, 'dnn'):\n",
    "        for layer in range(n_hidden_layers):\n",
    "            inputs = tf.layers.dense(inputs, n_neurons, activation = activation, kernel_initializer = initializer, name = \"hidden%d\" % (layer + 1))\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 28 * 28\n",
    "n_outputs = 5\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = (None, n_inputs), name = \"X\")\n",
    "y = tf.placeholder(tf.int64, shape = (None), name = \"y\")\n",
    "\n",
    "dnn_outputs = dnn(X)\n",
    "\n",
    "logits = tf.layers.dense(dnn_outputs, n_outputs, kernel_initializer = he_init, name = 'logits')\n",
    "Y_proba = tf.nn.softmax(logits, name = 'Y_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 8b) Use Adam optimization and early stopping to trian MNIST for digits 0 to 3\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, logits = logits)\n",
    "    loss = tf.reduce_mean(xentropy, name = 'loss')\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss, name = 'training_op')\n",
    "    \n",
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name = 'accuracy')\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train1 = mnist.train.images[mnist.train.labels < 5]\n",
    "y_train1 = mnist.train.labels[mnist.train.labels < 5]\n",
    "X_valid1 = mnist.validation.images[mnist.validation.labels < 5]\n",
    "y_valid1 = mnist.validation.labels[mnist.validation.labels < 5]\n",
    "X_test1 = mnist.test.images[mnist.test.labels < 5]\n",
    "y_test1 = mnist.test.labels[mnist.test.labels < 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.227003\tBest loss: 0.227003\tAccuracy: 95.04%\n",
      "1\tValidation loss: 0.235784\tBest loss: 0.227003\tAccuracy: 95.78%\n",
      "2\tValidation loss: 0.122533\tBest loss: 0.122533\tAccuracy: 97.38%\n",
      "3\tValidation loss: 0.163384\tBest loss: 0.122533\tAccuracy: 95.62%\n",
      "4\tValidation loss: 0.108590\tBest loss: 0.108590\tAccuracy: 97.85%\n",
      "5\tValidation loss: 0.093206\tBest loss: 0.093206\tAccuracy: 98.05%\n",
      "6\tValidation loss: 0.161963\tBest loss: 0.093206\tAccuracy: 97.07%\n",
      "7\tValidation loss: 0.114235\tBest loss: 0.093206\tAccuracy: 97.69%\n",
      "8\tValidation loss: 0.733225\tBest loss: 0.093206\tAccuracy: 90.11%\n",
      "9\tValidation loss: 0.399503\tBest loss: 0.093206\tAccuracy: 96.01%\n",
      "10\tValidation loss: 0.332553\tBest loss: 0.093206\tAccuracy: 95.35%\n",
      "11\tValidation loss: 0.258545\tBest loss: 0.093206\tAccuracy: 96.13%\n",
      "12\tValidation loss: 0.385276\tBest loss: 0.093206\tAccuracy: 96.99%\n",
      "13\tValidation loss: 0.220626\tBest loss: 0.093206\tAccuracy: 96.91%\n",
      "14\tValidation loss: 0.203410\tBest loss: 0.093206\tAccuracy: 97.38%\n",
      "15\tValidation loss: 0.191378\tBest loss: 0.093206\tAccuracy: 96.99%\n",
      "16\tValidation loss: 0.247799\tBest loss: 0.093206\tAccuracy: 96.44%\n",
      "17\tValidation loss: 0.585928\tBest loss: 0.093206\tAccuracy: 77.33%\n",
      "18\tValidation loss: 0.578136\tBest loss: 0.093206\tAccuracy: 76.00%\n",
      "19\tValidation loss: 0.234508\tBest loss: 0.093206\tAccuracy: 98.12%\n",
      "20\tValidation loss: 0.603065\tBest loss: 0.093206\tAccuracy: 97.62%\n",
      "21\tValidation loss: 1.174638\tBest loss: 0.093206\tAccuracy: 37.49%\n",
      "22\tValidation loss: 1.634383\tBest loss: 0.093206\tAccuracy: 19.27%\n",
      "23\tValidation loss: 1.706851\tBest loss: 0.093206\tAccuracy: 19.51%\n",
      "24\tValidation loss: 1.734250\tBest loss: 0.093206\tAccuracy: 19.70%\n",
      "25\tValidation loss: 1.625775\tBest loss: 0.093206\tAccuracy: 23.10%\n",
      "Early stopping\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_0_to_4.ckpt\n",
      "Final test accuracy 98.52%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 20\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train1))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train1) // batch_size):\n",
    "            X_batch, y_batch = X_train1[rnd_indices], y_train1[rnd_indices]\n",
    "            sess.run(training_op, feed_dict = {X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict = {X: X_valid1, y:y_valid1})\n",
    "        \n",
    "        if loss_val < best_loss:\n",
    "            save_path = saver.save(sess, \"./my_mnist_model_0_to_4.ckpt\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(epoch, loss_val, best_loss, acc_val * 100))\n",
    "        \n",
    "        \n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_mnist_model_0_to_4.ckpt\")\n",
    "    acc_test = accuracy.eval(feed_dict = {X: X_test1, y: y_test1})\n",
    "    print(\"Final test accuracy {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8c) Tuning the hyperparameters using cross-validation\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "class DNNClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_hidden_layers = 5, n_neurons = 100, optimizer_class = tf.train.AdamOptimizer, learning_rate = 0.01, batch_size = 20, activation = tf.nn.elu, initializer = he_init, batch_norm_momentum = None, dropout_rate = None, random_state = None):\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.n_neurons = n_neurons\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.activation = activation\n",
    "        self.initializer = initializer\n",
    "        self.batch_norm_momentum = batch_norm_momentum\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.random_state = random_state\n",
    "        self._session = None\n",
    "        \n",
    "    def _dnn(self, inputs):\n",
    "        for layer in range(self.n_hidden_layers):\n",
    "            if self.dropout_rate:\n",
    "                inputs = tf.layers.dropout(inputs, self.dropout_rate, training = self._training)\n",
    "            inputs = tf.layers.dense(inputs, self.n_neurons, kernel_initializer = self.initializer, name = \"hidden%d\" % (layer + 1))\n",
    "            if self.batch_norm_momentum:\n",
    "                inputs = tf.layers.batch_normalization(inputs, momentum = self.batch_norm_momentum, training = self.training)\n",
    "                inputs = self.activation(inputs, name = \"hidden%d_out\" % (layer + 1))\n",
    "        return inputs\n",
    "    \n",
    "    def _build_graph(self, n_inputs, n_outputs):\n",
    "        if self.random_state is not None:\n",
    "            tf.set_random_seed(self.random_state)\n",
    "            np.random.seed(self.random_state)\n",
    "            \n",
    "        X = tf.placeholder(tf.float32, shape = (None, n_inputs), name = \"X\")\n",
    "        y = tf.placeholder(tf.int32, shape = (None), name = 'y')\n",
    "        \n",
    "        if self.batch_norm_momentum or self.dropout_rate:\n",
    "            self._training = tf.placeholder_with_default(False, shape = (), name = 'training')\n",
    "        else:\n",
    "            self._training = None\n",
    "            \n",
    "        dnn_outputs = self._dnn(X)\n",
    "        \n",
    "        logits = tf.layers.dense(dnn_outputs, n_outputs, kernel_initializer = he_init, name = 'logits')\n",
    "        \n",
    "        Y_proba = tf.nn.softmax(logits, name = 'Y_proba')\n",
    "        \n",
    "        xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, logits = logits)\n",
    "        \n",
    "        loss = tf.reduce_mean(xentropy, name = 'loss')\n",
    "        \n",
    "        optimzier = self.optimizer_class(learning_rate = self.learning_rate)\n",
    "        training_op = optimizer.minimize(loss)\n",
    "        \n",
    "        correct = tf.nn.in_top_k(logits, y, 1)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name = 'accuracy')\n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        self._X = self._y = X, y\n",
    "        self._Y_proba, self._loss = Y_proba, loss\n",
    "        self._training_op, self._accuracy = training_op, accuracy\n",
    "        self._init, self._saver = init, saver\n",
    "        \n",
    "    def close_session(self):\n",
    "        if self._session:\n",
    "            self._session.close()\n",
    "            \n",
    "    def _get_model_params(self):\n",
    "        with self._graph.as_default():\n",
    "            gvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "        return {gvar.op.name: value for gvar, value in zip(gvars, self._session.run(gvars))}\n",
    "    \n",
    "    def _restore_model_params(self, model_params):\n",
    "        gvar_names = list(model_params.keys())\n",
    "        assign_ops = {gvar_name: self._graph.get_operation_by_name(gvar_name + \"/Assign\") for gvar_name in gvar_names}\n",
    "        init_values = {gvar_name: assign_op.inputs[1] for gvar_name, assign_op in assign_ops.items()}\n",
    "        feed_dict = {init_values[gvar_name]: model_params[gvar_name] for gvar_name in gvar_names}\n",
    "        self._session.run(assign_ops, feed_dict = feed_dict)\n",
    "        \n",
    "    def fit(self, X, y, n_epochs = 100, X_valid = None, y_valid = None):\n",
    "    \n",
    "        self.close_session()\n",
    "        \n",
    "        n_inputs = X.shape[1]\n",
    "        self.classes_ = np.unique(y)\n",
    "        n_outputs = len(self.classes_)\n",
    "        self.class_to_index_ = {label: index\n",
    "                               for index, label in enumerate(self.classes_)}\n",
    "        y = np.array([self.class_to_index_[label] for label in y], dtype = np.int32)\n",
    "        self._graph = tf.Graph()\n",
    "        with self._graph.as_default():\n",
    "            self._build_graph(n_inputs, n_outputs)\n",
    "            extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        \n",
    "        max_checks_without_progress = 20\n",
    "        checks_without_progress = 0\n",
    "        best_loss = np.infty\n",
    "        best_params = None\n",
    "        \n",
    "        self._session = tf.Session(graph = self._graph)\n",
    "        with self._session.as_default() as sess:\n",
    "            self._init.run()\n",
    "            for epoch in range(n_epochs):\n",
    "                rnd_idx = np.random.permutation(len(X))\n",
    "                for rnd_indices in np.array_split(rnd_idx, len(X) // self.batch_size):\n",
    "                    X_batch, y_batch = X[rnd_indices], y[rnd_indices]\n",
    "                    feed_dict = {self._X: X_batch, self._y: y_batch}\n",
    "                    if self._training is not None:\n",
    "                        feed_dict[self._training] = True\n",
    "                    sess.run(self._training_op, feed_dict=feed_dict)\n",
    "                    if extra_update_ops:\n",
    "                        sess.run(extra_update_ops, feed_dict = feed_dict)\n",
    "                if X_valid is not None and y_valid is not None:\n",
    "                    loss_val, acc_val = sess.run([self._loss, self._accuracy], feed_dict = {self._X: X_valid, self._y : y_valid})\n",
    "                    if loss_val < best_loss:\n",
    "                        best_params = self._get_model_params()\n",
    "                        best_loss = loss_val\n",
    "                        checks_without_progress = 0\n",
    "                    else:\n",
    "                        checks_without_progress = 0\n",
    "                    print(\"{}\\tValidation: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(epoch. loss_val, best_loss, acc_val * 100))\n",
    "                    if checks_without_progress > max_checks_without_progress:\n",
    "                        print(\"Early stopping!\")\n",
    "                        break\n",
    "                else:\n",
    "                    loss_train, acc_train = sess.run([self._loss. self._accuracy], feed_dict = {self._X: X_batch, self._y: y_batch})\n",
    "                    print(\"{}\\tLast training batch loss: {:.6f}\\tAccuracy: {:.2f}%\".format(epoch, loss_train, acc_train * 100))\n",
    "        \n",
    "            if best_params:\n",
    "                self._restore_model_params(best_params)\n",
    "            return self\n",
    "            \n",
    "        def predict_proba(self, X):\n",
    "            if not self._session:\n",
    "                raise NotFittedError(\"This %s instance is not fitted yet\" % self._class_._name__)\n",
    "            \n",
    "            with self._session_as_default() as sess:\n",
    "                return self._Y_proba.eval(feed_dict = {self._X:X})\n",
    "            \n",
    "        def predict(self, X):\n",
    "            class_indices = np.argmax(self.predict_proba(X), axis = 1)\n",
    "            return np.array([[self.classes_[class_index]] for class_index in class_indices], np.int32)\n",
    "        \n",
    "        def save(self, path):\n",
    "            self._saver.save(self._session, path)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not flatten dictionary. Key had 2 elements, but value had 1 elements. Key: [<tf.Tensor 'X:0' shape=(?, 784) dtype=float32>, <tf.Tensor 'y:0' shape=<unknown> dtype=int32>], value: [array([0, 2, 0, 2, 1, 1, 4, 1, 4, 1, 3, 1, 1, 4, 3, 0, 4, 3, 1, 1, 1], dtype=int32)].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-0d5a886873d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdnn_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDNNClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdnn_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_valid1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_valid1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-4ed5b635631c>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, n_epochs, X_valid, y_valid)\u001b[0m\n\u001b[1;32m    111\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mextra_update_ops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_update_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0mfeed_handles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m       \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_dict_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mfeed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_val\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msubfeed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubfeed_val\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_feed_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mflatten_dict_items\u001b[0;34m(dictionary)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0;34m\"Could not flatten dictionary. Key had %d elements, but value had \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;34m\"%d elements. Key: %s, value: %s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             % (len(flat_i), len(flat_v), flat_i, flat_v))\n\u001b[0m\u001b[1;32m    250\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mnew_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_v\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflat_dictionary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Could not flatten dictionary. Key had 2 elements, but value had 1 elements. Key: [<tf.Tensor 'X:0' shape=(?, 784) dtype=float32>, <tf.Tensor 'y:0' shape=<unknown> dtype=int32>], value: [array([0, 2, 0, 2, 1, 1, 4, 1, 4, 1, 3, 1, 1, 4, 3, 0, 4, 3, 1, 1, 1], dtype=int32)]."
     ]
    }
   ],
   "source": [
    "dnn_clf = DNNClassifier(random_state = 42)\n",
    "dnn_clf.fit(X_train1, y_train1, n_epochs = 1000, X_valid = X_valid1, y_valid = y_valid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9793734189531037"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = dnn_clf.predict(X_test1)\n",
    "accuracy_score(y_test1, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "class DNNClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_hidden_layers=5, n_neurons=100, optimizer_class=tf.train.AdamOptimizer,\n",
    "                 learning_rate=0.01, batch_size=20, activation=tf.nn.elu, initializer=he_init,\n",
    "                 batch_norm_momentum=None, dropout_rate=None, random_state=None):\n",
    "        \"\"\"Initialize the DNNClassifier by simply storing all the hyperparameters.\"\"\"\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.n_neurons = n_neurons\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.activation = activation\n",
    "        self.initializer = initializer\n",
    "        self.batch_norm_momentum = batch_norm_momentum\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.random_state = random_state\n",
    "        self._session = None\n",
    "\n",
    "    def _dnn(self, inputs):\n",
    "        \"\"\"Build the hidden layers, with support for batch normalization and dropout.\"\"\"\n",
    "        for layer in range(self.n_hidden_layers):\n",
    "            if self.dropout_rate:\n",
    "                inputs = tf.layers.dropout(inputs, self.dropout_rate, training=self._training)\n",
    "            inputs = tf.layers.dense(inputs, self.n_neurons,\n",
    "                                     kernel_initializer=self.initializer,\n",
    "                                     name=\"hidden%d\" % (layer + 1))\n",
    "            if self.batch_norm_momentum:\n",
    "                inputs = tf.layers.batch_normalization(inputs, momentum=self.batch_norm_momentum,\n",
    "                                                       training=self._training)\n",
    "            inputs = self.activation(inputs, name=\"hidden%d_out\" % (layer + 1))\n",
    "        return inputs\n",
    "\n",
    "    def _build_graph(self, n_inputs, n_outputs):\n",
    "        \"\"\"Build the same model as earlier\"\"\"\n",
    "        if self.random_state is not None:\n",
    "            tf.set_random_seed(self.random_state)\n",
    "            np.random.seed(self.random_state)\n",
    "\n",
    "        X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "        y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "        if self.batch_norm_momentum or self.dropout_rate:\n",
    "            self._training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "        else:\n",
    "            self._training = None\n",
    "\n",
    "        dnn_outputs = self._dnn(X)\n",
    "\n",
    "        logits = tf.layers.dense(dnn_outputs, n_outputs, kernel_initializer=he_init, name=\"logits\")\n",
    "        Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "        xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                                  logits=logits)\n",
    "        loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "        optimizer = self.optimizer_class(learning_rate=self.learning_rate)\n",
    "        training_op = optimizer.minimize(loss)\n",
    "\n",
    "        correct = tf.nn.in_top_k(logits, y, 1)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        # Make the important operations available easily through instance variables\n",
    "        self._X, self._y = X, y\n",
    "        self._Y_proba, self._loss = Y_proba, loss\n",
    "        self._training_op, self._accuracy = training_op, accuracy\n",
    "        self._init, self._saver = init, saver\n",
    "\n",
    "    def close_session(self):\n",
    "        if self._session:\n",
    "            self._session.close()\n",
    "\n",
    "    def _get_model_params(self):\n",
    "        \"\"\"Get all variable values (used for early stopping, faster than saving to disk)\"\"\"\n",
    "        with self._graph.as_default():\n",
    "            gvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "        return {gvar.op.name: value for gvar, value in zip(gvars, self._session.run(gvars))}\n",
    "\n",
    "    def _restore_model_params(self, model_params):\n",
    "        \"\"\"Set all variables to the given values (for early stopping, faster than loading from disk)\"\"\"\n",
    "        gvar_names = list(model_params.keys())\n",
    "        assign_ops = {gvar_name: self._graph.get_operation_by_name(gvar_name + \"/Assign\")\n",
    "                      for gvar_name in gvar_names}\n",
    "        init_values = {gvar_name: assign_op.inputs[1] for gvar_name, assign_op in assign_ops.items()}\n",
    "        feed_dict = {init_values[gvar_name]: model_params[gvar_name] for gvar_name in gvar_names}\n",
    "        self._session.run(assign_ops, feed_dict=feed_dict)\n",
    "\n",
    "    def fit(self, X, y, n_epochs=100, X_valid=None, y_valid=None):\n",
    "        \"\"\"Fit the model to the training set. If X_valid and y_valid are provided, use early stopping.\"\"\"\n",
    "        self.close_session()\n",
    "\n",
    "        # infer n_inputs and n_outputs from the training set.\n",
    "        n_inputs = X.shape[1]\n",
    "        self.classes_ = np.unique(y)\n",
    "        n_outputs = len(self.classes_)\n",
    "        \n",
    "        # Translate the labels vector to a vector of sorted class indices, containing\n",
    "        # integers from 0 to n_outputs - 1.\n",
    "        # For example, if y is equal to [8, 8, 9, 5, 7, 6, 6, 6], then the sorted class\n",
    "        # labels (self.classes_) will be equal to [5, 6, 7, 8, 9], and the labels vector\n",
    "        # will be translated to [3, 3, 4, 0, 2, 1, 1, 1]\n",
    "        self.class_to_index_ = {label: index\n",
    "                                for index, label in enumerate(self.classes_)}\n",
    "        y = np.array([self.class_to_index_[label]\n",
    "                      for label in y], dtype=np.int32)\n",
    "        \n",
    "        self._graph = tf.Graph()\n",
    "        with self._graph.as_default():\n",
    "            self._build_graph(n_inputs, n_outputs)\n",
    "            # extra ops for batch normalization\n",
    "            extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "        # needed in case of early stopping\n",
    "        max_checks_without_progress = 20\n",
    "        checks_without_progress = 0\n",
    "        best_loss = np.infty\n",
    "        best_params = None\n",
    "        \n",
    "        # Now train the model!\n",
    "        self._session = tf.Session(graph=self._graph)\n",
    "        with self._session.as_default() as sess:\n",
    "            self._init.run()\n",
    "            for epoch in range(n_epochs):\n",
    "                rnd_idx = np.random.permutation(len(X))\n",
    "                for rnd_indices in np.array_split(rnd_idx, len(X) // self.batch_size):\n",
    "                    X_batch, y_batch = X[rnd_indices], y[rnd_indices]\n",
    "                    feed_dict = {self._X: X_batch, self._y: y_batch}\n",
    "                    if self._training is not None:\n",
    "                        feed_dict[self._training] = True\n",
    "                    sess.run(self._training_op, feed_dict=feed_dict)\n",
    "                    if extra_update_ops:\n",
    "                        sess.run(extra_update_ops, feed_dict=feed_dict)\n",
    "                if X_valid is not None and y_valid is not None:\n",
    "                    loss_val, acc_val = sess.run([self._loss, self._accuracy],\n",
    "                                                 feed_dict={self._X: X_valid,\n",
    "                                                            self._y: y_valid})\n",
    "                    if loss_val < best_loss:\n",
    "                        best_params = self._get_model_params()\n",
    "                        best_loss = loss_val\n",
    "                        checks_without_progress = 0\n",
    "                    else:\n",
    "                        checks_without_progress += 1\n",
    "                    print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "                        epoch, loss_val, best_loss, acc_val * 100))\n",
    "                    if checks_without_progress > max_checks_without_progress:\n",
    "                        print(\"Early stopping!\")\n",
    "                        break\n",
    "                else:\n",
    "                    loss_train, acc_train = sess.run([self._loss, self._accuracy],\n",
    "                                                     feed_dict={self._X: X_batch,\n",
    "                                                                self._y: y_batch})\n",
    "                    print(\"{}\\tLast training batch loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "                        epoch, loss_train, acc_train * 100))\n",
    "            # If we used early stopping then rollback to the best model found\n",
    "            if best_params:\n",
    "                self._restore_model_params(best_params)\n",
    "            return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if not self._session:\n",
    "            raise NotFittedError(\"This %s instance is not fitted yet\" % self.__class__.__name__)\n",
    "        with self._session.as_default() as sess:\n",
    "            return self._Y_proba.eval(feed_dict={self._X: X})\n",
    "\n",
    "    def predict(self, X):\n",
    "        class_indices = np.argmax(self.predict_proba(X), axis=1)\n",
    "        return np.array([[self.classes_[class_index]]\n",
    "                         for class_index in class_indices], np.int32)\n",
    "\n",
    "    def save(self, path):\n",
    "        self._saver.save(self._session, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mqbssra6/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/sklearn/model_selection/_search.py:583: DeprecationWarning: \"fit_params\" as a constructor argument was deprecated in version 0.19 and will be removed in version 0.21. Pass fit parameters to the \"fit\" method instead.\n",
      "  '\"fit\" method instead.', DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[CV] n_neurons=10, learning_rate=0.05, batch_size=100, activation=<function elu at 0x1099692f0> \n",
      "0\tValidation loss: 0.133020\tBest loss: 0.133020\tAccuracy: 96.40%\n",
      "1\tValidation loss: 0.153023\tBest loss: 0.133020\tAccuracy: 95.78%\n",
      "2\tValidation loss: 0.137756\tBest loss: 0.133020\tAccuracy: 96.44%\n",
      "3\tValidation loss: 0.113295\tBest loss: 0.113295\tAccuracy: 96.60%\n",
      "4\tValidation loss: 0.134245\tBest loss: 0.113295\tAccuracy: 96.68%\n",
      "5\tValidation loss: 0.160136\tBest loss: 0.113295\tAccuracy: 96.48%\n",
      "6\tValidation loss: 1.205526\tBest loss: 0.113295\tAccuracy: 58.29%\n",
      "7\tValidation loss: 0.854387\tBest loss: 0.113295\tAccuracy: 58.44%\n",
      "8\tValidation loss: 1.618615\tBest loss: 0.113295\tAccuracy: 19.27%\n",
      "9\tValidation loss: 1.610767\tBest loss: 0.113295\tAccuracy: 22.01%\n",
      "10\tValidation loss: 1.613220\tBest loss: 0.113295\tAccuracy: 19.27%\n",
      "11\tValidation loss: 1.611311\tBest loss: 0.113295\tAccuracy: 22.01%\n",
      "12\tValidation loss: 1.627571\tBest loss: 0.113295\tAccuracy: 22.01%\n",
      "13\tValidation loss: 1.642730\tBest loss: 0.113295\tAccuracy: 18.73%\n",
      "14\tValidation loss: 1.615385\tBest loss: 0.113295\tAccuracy: 18.73%\n",
      "15\tValidation loss: 1.616827\tBest loss: 0.113295\tAccuracy: 22.01%\n",
      "16\tValidation loss: 1.609228\tBest loss: 0.113295\tAccuracy: 22.01%\n",
      "17\tValidation loss: 1.615682\tBest loss: 0.113295\tAccuracy: 19.27%\n",
      "18\tValidation loss: 1.614222\tBest loss: 0.113295\tAccuracy: 18.73%\n",
      "19\tValidation loss: 1.622343\tBest loss: 0.113295\tAccuracy: 22.01%\n",
      "20\tValidation loss: 1.629349\tBest loss: 0.113295\tAccuracy: 19.08%\n",
      "21\tValidation loss: 1.625753\tBest loss: 0.113295\tAccuracy: 19.27%\n",
      "22\tValidation loss: 1.621231\tBest loss: 0.113295\tAccuracy: 18.73%\n",
      "23\tValidation loss: 1.614291\tBest loss: 0.113295\tAccuracy: 20.91%\n",
      "24\tValidation loss: 1.622918\tBest loss: 0.113295\tAccuracy: 22.01%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, learning_rate=0.05, batch_size=100, activation=<function elu at 0x1099692f0>, total=  10.6s\n",
      "[CV] n_neurons=10, learning_rate=0.05, batch_size=100, activation=<function elu at 0x1099692f0> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.151885\tBest loss: 0.151885\tAccuracy: 95.62%\n",
      "1\tValidation loss: 0.108809\tBest loss: 0.108809\tAccuracy: 96.83%\n",
      "2\tValidation loss: 0.117152\tBest loss: 0.108809\tAccuracy: 96.99%\n",
      "3\tValidation loss: 0.147208\tBest loss: 0.108809\tAccuracy: 96.52%\n",
      "4\tValidation loss: 0.140152\tBest loss: 0.108809\tAccuracy: 96.36%\n",
      "5\tValidation loss: 0.141784\tBest loss: 0.108809\tAccuracy: 96.44%\n",
      "6\tValidation loss: 1.561300\tBest loss: 0.108809\tAccuracy: 39.44%\n",
      "7\tValidation loss: 1.164626\tBest loss: 0.108809\tAccuracy: 39.80%\n",
      "8\tValidation loss: 1.150888\tBest loss: 0.108809\tAccuracy: 40.15%\n",
      "9\tValidation loss: 1.150942\tBest loss: 0.108809\tAccuracy: 40.15%\n",
      "10\tValidation loss: 1.135206\tBest loss: 0.108809\tAccuracy: 42.49%\n",
      "11\tValidation loss: 1.158850\tBest loss: 0.108809\tAccuracy: 40.23%\n",
      "12\tValidation loss: 1.142637\tBest loss: 0.108809\tAccuracy: 42.34%\n",
      "13\tValidation loss: 1.173786\tBest loss: 0.108809\tAccuracy: 40.27%\n",
      "14\tValidation loss: 1.146071\tBest loss: 0.108809\tAccuracy: 42.30%\n",
      "15\tValidation loss: 1.679023\tBest loss: 0.108809\tAccuracy: 18.73%\n",
      "16\tValidation loss: 1.617953\tBest loss: 0.108809\tAccuracy: 22.01%\n",
      "17\tValidation loss: 1.615995\tBest loss: 0.108809\tAccuracy: 19.08%\n",
      "18\tValidation loss: 1.610315\tBest loss: 0.108809\tAccuracy: 22.01%\n",
      "19\tValidation loss: 1.612572\tBest loss: 0.108809\tAccuracy: 22.01%\n",
      "20\tValidation loss: 1.609411\tBest loss: 0.108809\tAccuracy: 22.01%\n",
      "21\tValidation loss: 1.653062\tBest loss: 0.108809\tAccuracy: 22.01%\n",
      "22\tValidation loss: 1.622337\tBest loss: 0.108809\tAccuracy: 19.27%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, learning_rate=0.05, batch_size=100, activation=<function elu at 0x1099692f0>, total=   9.9s\n",
      "[CV] n_neurons=10, learning_rate=0.05, batch_size=100, activation=<function elu at 0x1099692f0> \n",
      "0\tValidation loss: 0.176190\tBest loss: 0.176190\tAccuracy: 94.68%\n",
      "1\tValidation loss: 0.199664\tBest loss: 0.176190\tAccuracy: 94.92%\n",
      "2\tValidation loss: 0.150524\tBest loss: 0.150524\tAccuracy: 95.90%\n",
      "3\tValidation loss: 0.204128\tBest loss: 0.150524\tAccuracy: 95.62%\n",
      "4\tValidation loss: 0.180253\tBest loss: 0.150524\tAccuracy: 94.88%\n",
      "5\tValidation loss: 0.159958\tBest loss: 0.150524\tAccuracy: 95.54%\n",
      "6\tValidation loss: 0.131734\tBest loss: 0.131734\tAccuracy: 96.76%\n",
      "7\tValidation loss: 0.145623\tBest loss: 0.131734\tAccuracy: 96.60%\n",
      "8\tValidation loss: 1.632372\tBest loss: 0.131734\tAccuracy: 19.27%\n",
      "9\tValidation loss: 1.634999\tBest loss: 0.131734\tAccuracy: 22.01%\n",
      "10\tValidation loss: 1.637999\tBest loss: 0.131734\tAccuracy: 22.01%\n",
      "11\tValidation loss: 1.643709\tBest loss: 0.131734\tAccuracy: 22.01%\n",
      "12\tValidation loss: 1.647845\tBest loss: 0.131734\tAccuracy: 20.91%\n",
      "13\tValidation loss: 1.640854\tBest loss: 0.131734\tAccuracy: 20.91%\n",
      "14\tValidation loss: 1.613795\tBest loss: 0.131734\tAccuracy: 22.01%\n",
      "15\tValidation loss: 1.622489\tBest loss: 0.131734\tAccuracy: 22.01%\n",
      "16\tValidation loss: 1.657225\tBest loss: 0.131734\tAccuracy: 22.01%\n",
      "17\tValidation loss: 1.633074\tBest loss: 0.131734\tAccuracy: 19.08%\n",
      "18\tValidation loss: 1.609699\tBest loss: 0.131734\tAccuracy: 22.01%\n",
      "19\tValidation loss: 1.615258\tBest loss: 0.131734\tAccuracy: 19.08%\n",
      "20\tValidation loss: 1.619368\tBest loss: 0.131734\tAccuracy: 19.27%\n",
      "21\tValidation loss: 1.639568\tBest loss: 0.131734\tAccuracy: 22.01%\n",
      "22\tValidation loss: 1.613815\tBest loss: 0.131734\tAccuracy: 22.01%\n",
      "23\tValidation loss: 1.621760\tBest loss: 0.131734\tAccuracy: 22.01%\n",
      "24\tValidation loss: 1.607763\tBest loss: 0.131734\tAccuracy: 20.91%\n",
      "25\tValidation loss: 1.615470\tBest loss: 0.131734\tAccuracy: 18.73%\n",
      "26\tValidation loss: 1.610164\tBest loss: 0.131734\tAccuracy: 20.91%\n",
      "27\tValidation loss: 1.624272\tBest loss: 0.131734\tAccuracy: 22.01%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, learning_rate=0.05, batch_size=100, activation=<function elu at 0x1099692f0>, total=  11.2s\n",
      "[CV] n_neurons=30, learning_rate=0.02, batch_size=500, activation=<function relu at 0x10998d488> \n",
      "0\tValidation loss: 0.171513\tBest loss: 0.171513\tAccuracy: 95.07%\n",
      "1\tValidation loss: 0.095900\tBest loss: 0.095900\tAccuracy: 97.03%\n",
      "2\tValidation loss: 0.097555\tBest loss: 0.095900\tAccuracy: 97.03%\n",
      "3\tValidation loss: 0.090976\tBest loss: 0.090976\tAccuracy: 97.15%\n",
      "4\tValidation loss: 0.075701\tBest loss: 0.075701\tAccuracy: 97.93%\n",
      "5\tValidation loss: 0.070658\tBest loss: 0.070658\tAccuracy: 97.69%\n",
      "6\tValidation loss: 0.073057\tBest loss: 0.070658\tAccuracy: 98.12%\n",
      "7\tValidation loss: 0.070251\tBest loss: 0.070251\tAccuracy: 97.93%\n",
      "8\tValidation loss: 0.074210\tBest loss: 0.070251\tAccuracy: 98.51%\n",
      "9\tValidation loss: 0.074874\tBest loss: 0.070251\tAccuracy: 98.51%\n",
      "10\tValidation loss: 0.093508\tBest loss: 0.070251\tAccuracy: 97.65%\n",
      "11\tValidation loss: 0.064262\tBest loss: 0.064262\tAccuracy: 98.12%\n",
      "12\tValidation loss: 0.075064\tBest loss: 0.064262\tAccuracy: 97.89%\n",
      "13\tValidation loss: 0.081701\tBest loss: 0.064262\tAccuracy: 97.97%\n",
      "14\tValidation loss: 0.102396\tBest loss: 0.064262\tAccuracy: 97.65%\n",
      "15\tValidation loss: 0.094451\tBest loss: 0.064262\tAccuracy: 97.89%\n",
      "16\tValidation loss: 0.080241\tBest loss: 0.064262\tAccuracy: 98.24%\n",
      "17\tValidation loss: 0.104454\tBest loss: 0.064262\tAccuracy: 97.34%\n",
      "18\tValidation loss: 0.070982\tBest loss: 0.064262\tAccuracy: 98.20%\n",
      "19\tValidation loss: 0.086396\tBest loss: 0.064262\tAccuracy: 98.44%\n",
      "20\tValidation loss: 0.086355\tBest loss: 0.064262\tAccuracy: 97.97%\n",
      "21\tValidation loss: 0.081647\tBest loss: 0.064262\tAccuracy: 98.08%\n",
      "22\tValidation loss: 0.078978\tBest loss: 0.064262\tAccuracy: 98.16%\n",
      "23\tValidation loss: 0.104769\tBest loss: 0.064262\tAccuracy: 97.69%\n",
      "24\tValidation loss: 0.096131\tBest loss: 0.064262\tAccuracy: 98.24%\n",
      "25\tValidation loss: 0.089278\tBest loss: 0.064262\tAccuracy: 98.40%\n",
      "26\tValidation loss: 0.122779\tBest loss: 0.064262\tAccuracy: 97.19%\n",
      "27\tValidation loss: 0.088307\tBest loss: 0.064262\tAccuracy: 98.20%\n",
      "28\tValidation loss: 0.091587\tBest loss: 0.064262\tAccuracy: 98.05%\n",
      "29\tValidation loss: 0.117975\tBest loss: 0.064262\tAccuracy: 98.36%\n",
      "30\tValidation loss: 0.085824\tBest loss: 0.064262\tAccuracy: 98.36%\n",
      "31\tValidation loss: 0.111376\tBest loss: 0.064262\tAccuracy: 97.77%\n",
      "32\tValidation loss: 0.132046\tBest loss: 0.064262\tAccuracy: 98.28%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, learning_rate=0.02, batch_size=500, activation=<function relu at 0x10998d488>, total=   8.3s\n",
      "[CV] n_neurons=30, learning_rate=0.02, batch_size=500, activation=<function relu at 0x10998d488> \n",
      "0\tValidation loss: 0.113188\tBest loss: 0.113188\tAccuracy: 96.60%\n",
      "1\tValidation loss: 0.081384\tBest loss: 0.081384\tAccuracy: 97.58%\n",
      "2\tValidation loss: 0.068770\tBest loss: 0.068770\tAccuracy: 98.12%\n",
      "3\tValidation loss: 0.077317\tBest loss: 0.068770\tAccuracy: 97.73%\n",
      "4\tValidation loss: 0.074333\tBest loss: 0.068770\tAccuracy: 97.97%\n",
      "5\tValidation loss: 0.084735\tBest loss: 0.068770\tAccuracy: 97.30%\n",
      "6\tValidation loss: 0.082890\tBest loss: 0.068770\tAccuracy: 97.69%\n",
      "7\tValidation loss: 0.076902\tBest loss: 0.068770\tAccuracy: 97.69%\n",
      "8\tValidation loss: 0.078174\tBest loss: 0.068770\tAccuracy: 97.85%\n",
      "9\tValidation loss: 0.111932\tBest loss: 0.068770\tAccuracy: 96.83%\n",
      "10\tValidation loss: 0.068804\tBest loss: 0.068770\tAccuracy: 98.20%\n",
      "11\tValidation loss: 0.058042\tBest loss: 0.058042\tAccuracy: 98.59%\n",
      "12\tValidation loss: 0.080868\tBest loss: 0.058042\tAccuracy: 98.05%\n",
      "13\tValidation loss: 0.056953\tBest loss: 0.056953\tAccuracy: 98.40%\n",
      "14\tValidation loss: 0.085263\tBest loss: 0.056953\tAccuracy: 97.85%\n",
      "15\tValidation loss: 0.073558\tBest loss: 0.056953\tAccuracy: 98.36%\n",
      "16\tValidation loss: 0.080923\tBest loss: 0.056953\tAccuracy: 98.16%\n",
      "17\tValidation loss: 0.064859\tBest loss: 0.056953\tAccuracy: 98.36%\n",
      "18\tValidation loss: 0.084925\tBest loss: 0.056953\tAccuracy: 98.28%\n",
      "19\tValidation loss: 0.080949\tBest loss: 0.056953\tAccuracy: 98.08%\n",
      "20\tValidation loss: 0.073728\tBest loss: 0.056953\tAccuracy: 98.40%\n",
      "21\tValidation loss: 0.069459\tBest loss: 0.056953\tAccuracy: 98.40%\n",
      "22\tValidation loss: 0.098572\tBest loss: 0.056953\tAccuracy: 98.12%\n",
      "23\tValidation loss: 0.101230\tBest loss: 0.056953\tAccuracy: 97.85%\n",
      "24\tValidation loss: 0.077436\tBest loss: 0.056953\tAccuracy: 98.01%\n",
      "25\tValidation loss: 0.077748\tBest loss: 0.056953\tAccuracy: 98.12%\n",
      "26\tValidation loss: 0.080190\tBest loss: 0.056953\tAccuracy: 98.44%\n",
      "27\tValidation loss: 0.095348\tBest loss: 0.056953\tAccuracy: 98.24%\n",
      "28\tValidation loss: 0.152502\tBest loss: 0.056953\tAccuracy: 97.77%\n",
      "29\tValidation loss: 0.081558\tBest loss: 0.056953\tAccuracy: 98.44%\n",
      "30\tValidation loss: 0.092452\tBest loss: 0.056953\tAccuracy: 98.36%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\tValidation loss: 0.078109\tBest loss: 0.056953\tAccuracy: 98.40%\n",
      "32\tValidation loss: 0.100915\tBest loss: 0.056953\tAccuracy: 98.36%\n",
      "33\tValidation loss: 0.077558\tBest loss: 0.056953\tAccuracy: 98.36%\n",
      "34\tValidation loss: 0.100731\tBest loss: 0.056953\tAccuracy: 98.20%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, learning_rate=0.02, batch_size=500, activation=<function relu at 0x10998d488>, total=   8.7s\n",
      "[CV] n_neurons=30, learning_rate=0.02, batch_size=500, activation=<function relu at 0x10998d488> \n",
      "0\tValidation loss: 0.121159\tBest loss: 0.121159\tAccuracy: 96.68%\n",
      "1\tValidation loss: 0.093012\tBest loss: 0.093012\tAccuracy: 97.11%\n",
      "2\tValidation loss: 0.084517\tBest loss: 0.084517\tAccuracy: 97.50%\n",
      "3\tValidation loss: 0.070080\tBest loss: 0.070080\tAccuracy: 97.58%\n",
      "4\tValidation loss: 0.073499\tBest loss: 0.070080\tAccuracy: 97.69%\n",
      "5\tValidation loss: 0.077686\tBest loss: 0.070080\tAccuracy: 97.93%\n",
      "6\tValidation loss: 0.063263\tBest loss: 0.063263\tAccuracy: 98.20%\n",
      "7\tValidation loss: 0.066538\tBest loss: 0.063263\tAccuracy: 97.93%\n",
      "8\tValidation loss: 0.095430\tBest loss: 0.063263\tAccuracy: 97.30%\n",
      "9\tValidation loss: 0.069840\tBest loss: 0.063263\tAccuracy: 98.08%\n",
      "10\tValidation loss: 0.070187\tBest loss: 0.063263\tAccuracy: 97.77%\n",
      "11\tValidation loss: 0.072014\tBest loss: 0.063263\tAccuracy: 98.28%\n",
      "12\tValidation loss: 0.077024\tBest loss: 0.063263\tAccuracy: 98.12%\n",
      "13\tValidation loss: 0.073017\tBest loss: 0.063263\tAccuracy: 98.24%\n",
      "14\tValidation loss: 0.105023\tBest loss: 0.063263\tAccuracy: 97.77%\n",
      "15\tValidation loss: 0.064104\tBest loss: 0.063263\tAccuracy: 98.40%\n",
      "16\tValidation loss: 0.076903\tBest loss: 0.063263\tAccuracy: 98.28%\n",
      "17\tValidation loss: 0.079097\tBest loss: 0.063263\tAccuracy: 97.85%\n",
      "18\tValidation loss: 0.068662\tBest loss: 0.063263\tAccuracy: 98.24%\n",
      "19\tValidation loss: 0.085785\tBest loss: 0.063263\tAccuracy: 97.97%\n",
      "20\tValidation loss: 0.075248\tBest loss: 0.063263\tAccuracy: 98.20%\n",
      "21\tValidation loss: 0.080703\tBest loss: 0.063263\tAccuracy: 98.08%\n",
      "22\tValidation loss: 0.069105\tBest loss: 0.063263\tAccuracy: 98.28%\n",
      "23\tValidation loss: 0.107339\tBest loss: 0.063263\tAccuracy: 98.16%\n",
      "24\tValidation loss: 0.097046\tBest loss: 0.063263\tAccuracy: 98.32%\n",
      "25\tValidation loss: 0.083067\tBest loss: 0.063263\tAccuracy: 98.12%\n",
      "26\tValidation loss: 0.103586\tBest loss: 0.063263\tAccuracy: 98.16%\n",
      "27\tValidation loss: 0.079554\tBest loss: 0.063263\tAccuracy: 98.44%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, learning_rate=0.02, batch_size=500, activation=<function relu at 0x10998d488>, total=   7.0s\n",
      "[CV] n_neurons=90, learning_rate=0.05, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1a16fccf28> \n",
      "0\tValidation loss: 665.485657\tBest loss: 665.485657\tAccuracy: 18.73%\n",
      "1\tValidation loss: 1.076261\tBest loss: 1.076261\tAccuracy: 59.89%\n",
      "2\tValidation loss: 0.746253\tBest loss: 0.746253\tAccuracy: 69.66%\n",
      "3\tValidation loss: 0.847762\tBest loss: 0.746253\tAccuracy: 68.61%\n",
      "4\tValidation loss: 0.674476\tBest loss: 0.674476\tAccuracy: 71.74%\n",
      "5\tValidation loss: 0.575160\tBest loss: 0.575160\tAccuracy: 80.10%\n",
      "6\tValidation loss: 0.828513\tBest loss: 0.575160\tAccuracy: 66.15%\n",
      "7\tValidation loss: 0.666459\tBest loss: 0.575160\tAccuracy: 73.30%\n",
      "8\tValidation loss: 0.532283\tBest loss: 0.532283\tAccuracy: 81.43%\n",
      "9\tValidation loss: 0.453792\tBest loss: 0.453792\tAccuracy: 85.69%\n",
      "10\tValidation loss: 336.247925\tBest loss: 0.453792\tAccuracy: 51.17%\n",
      "11\tValidation loss: 129.156815\tBest loss: 0.453792\tAccuracy: 53.40%\n",
      "12\tValidation loss: 19.915245\tBest loss: 0.453792\tAccuracy: 59.38%\n",
      "13\tValidation loss: 21.953173\tBest loss: 0.453792\tAccuracy: 59.97%\n",
      "14\tValidation loss: 12.889620\tBest loss: 0.453792\tAccuracy: 65.72%\n",
      "15\tValidation loss: 27.152157\tBest loss: 0.453792\tAccuracy: 55.16%\n",
      "16\tValidation loss: 18.919336\tBest loss: 0.453792\tAccuracy: 69.47%\n",
      "17\tValidation loss: 24.157799\tBest loss: 0.453792\tAccuracy: 59.46%\n",
      "18\tValidation loss: 19.136135\tBest loss: 0.453792\tAccuracy: 64.39%\n",
      "19\tValidation loss: 16.270113\tBest loss: 0.453792\tAccuracy: 57.54%\n",
      "20\tValidation loss: 6.644347\tBest loss: 0.453792\tAccuracy: 78.58%\n",
      "21\tValidation loss: 4.890314\tBest loss: 0.453792\tAccuracy: 83.85%\n",
      "22\tValidation loss: 4.333772\tBest loss: 0.453792\tAccuracy: 80.38%\n",
      "23\tValidation loss: 4.152594\tBest loss: 0.453792\tAccuracy: 82.37%\n",
      "24\tValidation loss: 5.493657\tBest loss: 0.453792\tAccuracy: 77.87%\n",
      "25\tValidation loss: 2283.213379\tBest loss: 0.453792\tAccuracy: 53.44%\n",
      "26\tValidation loss: 58.745834\tBest loss: 0.453792\tAccuracy: 63.06%\n",
      "27\tValidation loss: 132.108246\tBest loss: 0.453792\tAccuracy: 54.93%\n",
      "28\tValidation loss: 33.168461\tBest loss: 0.453792\tAccuracy: 73.65%\n",
      "29\tValidation loss: 28.192350\tBest loss: 0.453792\tAccuracy: 60.91%\n",
      "30\tValidation loss: 32.011162\tBest loss: 0.453792\tAccuracy: 67.01%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, learning_rate=0.05, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1a16fccf28>, total=  49.5s\n",
      "[CV] n_neurons=90, learning_rate=0.05, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1a16fccf28> \n",
      "0\tValidation loss: 10422.260742\tBest loss: 10422.260742\tAccuracy: 23.81%\n",
      "1\tValidation loss: 11.556370\tBest loss: 11.556370\tAccuracy: 51.56%\n",
      "2\tValidation loss: 3.978382\tBest loss: 3.978382\tAccuracy: 75.14%\n",
      "3\tValidation loss: 13.468793\tBest loss: 3.978382\tAccuracy: 57.82%\n",
      "4\tValidation loss: 1.518749\tBest loss: 1.518749\tAccuracy: 88.12%\n",
      "5\tValidation loss: 93410.507812\tBest loss: 1.518749\tAccuracy: 18.69%\n",
      "6\tValidation loss: 1898.095947\tBest loss: 1.518749\tAccuracy: 37.14%\n",
      "7\tValidation loss: 287.428192\tBest loss: 1.518749\tAccuracy: 43.24%\n",
      "8\tValidation loss: 270.251312\tBest loss: 1.518749\tAccuracy: 43.35%\n",
      "9\tValidation loss: 910.740540\tBest loss: 1.518749\tAccuracy: 37.57%\n",
      "10\tValidation loss: 143.796448\tBest loss: 1.518749\tAccuracy: 57.82%\n",
      "11\tValidation loss: 123.277000\tBest loss: 1.518749\tAccuracy: 50.04%\n",
      "12\tValidation loss: 9970.572266\tBest loss: 1.518749\tAccuracy: 27.99%\n",
      "13\tValidation loss: 423.432220\tBest loss: 1.518749\tAccuracy: 37.72%\n",
      "14\tValidation loss: 110.476700\tBest loss: 1.518749\tAccuracy: 53.95%\n",
      "15\tValidation loss: 105.239296\tBest loss: 1.518749\tAccuracy: 59.66%\n",
      "16\tValidation loss: 150.718109\tBest loss: 1.518749\tAccuracy: 48.28%\n",
      "17\tValidation loss: 47.910046\tBest loss: 1.518749\tAccuracy: 61.92%\n",
      "18\tValidation loss: 25.108837\tBest loss: 1.518749\tAccuracy: 76.23%\n",
      "19\tValidation loss: 61.865746\tBest loss: 1.518749\tAccuracy: 59.73%\n",
      "20\tValidation loss: 24.505453\tBest loss: 1.518749\tAccuracy: 76.39%\n",
      "21\tValidation loss: 32.080563\tBest loss: 1.518749\tAccuracy: 70.37%\n",
      "22\tValidation loss: 9074.900391\tBest loss: 1.518749\tAccuracy: 37.22%\n",
      "23\tValidation loss: 81.501297\tBest loss: 1.518749\tAccuracy: 53.21%\n",
      "24\tValidation loss: 55.978683\tBest loss: 1.518749\tAccuracy: 60.28%\n",
      "25\tValidation loss: 39.277023\tBest loss: 1.518749\tAccuracy: 63.88%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, learning_rate=0.05, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1a16fccf28>, total=  41.0s\n",
      "[CV] n_neurons=90, learning_rate=0.05, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1a16fccf28> \n",
      "0\tValidation loss: 1585.608032\tBest loss: 1585.608032\tAccuracy: 30.49%\n",
      "1\tValidation loss: 12.079154\tBest loss: 12.079154\tAccuracy: 73.77%\n",
      "2\tValidation loss: 3.492914\tBest loss: 3.492914\tAccuracy: 76.51%\n",
      "3\tValidation loss: 2.357495\tBest loss: 2.357495\tAccuracy: 81.20%\n",
      "4\tValidation loss: 2.501446\tBest loss: 2.357495\tAccuracy: 77.40%\n",
      "5\tValidation loss: 1.091716\tBest loss: 1.091716\tAccuracy: 84.01%\n",
      "6\tValidation loss: 0.975053\tBest loss: 0.975053\tAccuracy: 87.02%\n",
      "7\tValidation loss: 0.647081\tBest loss: 0.647081\tAccuracy: 86.24%\n",
      "8\tValidation loss: 0.510507\tBest loss: 0.510507\tAccuracy: 89.09%\n",
      "9\tValidation loss: 0.674725\tBest loss: 0.510507\tAccuracy: 86.63%\n",
      "10\tValidation loss: 0.387978\tBest loss: 0.387978\tAccuracy: 90.73%\n",
      "11\tValidation loss: 0.328711\tBest loss: 0.328711\tAccuracy: 92.10%\n",
      "12\tValidation loss: 0.415100\tBest loss: 0.328711\tAccuracy: 89.44%\n",
      "13\tValidation loss: 0.351510\tBest loss: 0.328711\tAccuracy: 91.16%\n",
      "14\tValidation loss: 333.155609\tBest loss: 0.328711\tAccuracy: 22.32%\n",
      "15\tValidation loss: 9.054622\tBest loss: 0.328711\tAccuracy: 54.61%\n",
      "16\tValidation loss: 7.385711\tBest loss: 0.328711\tAccuracy: 62.90%\n",
      "17\tValidation loss: 7.793758\tBest loss: 0.328711\tAccuracy: 58.72%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\tValidation loss: 4.937276\tBest loss: 0.328711\tAccuracy: 69.16%\n",
      "19\tValidation loss: 6.343340\tBest loss: 0.328711\tAccuracy: 60.36%\n",
      "20\tValidation loss: 2.815907\tBest loss: 0.328711\tAccuracy: 66.54%\n",
      "21\tValidation loss: 61.898945\tBest loss: 0.328711\tAccuracy: 30.61%\n",
      "22\tValidation loss: 2.002695\tBest loss: 0.328711\tAccuracy: 74.35%\n",
      "23\tValidation loss: 1.484913\tBest loss: 0.328711\tAccuracy: 76.43%\n",
      "24\tValidation loss: 1.078764\tBest loss: 0.328711\tAccuracy: 82.53%\n",
      "25\tValidation loss: 1.479109\tBest loss: 0.328711\tAccuracy: 85.89%\n",
      "26\tValidation loss: 35.164253\tBest loss: 0.328711\tAccuracy: 41.87%\n",
      "27\tValidation loss: 15440.137695\tBest loss: 0.328711\tAccuracy: 18.73%\n",
      "28\tValidation loss: 339.888580\tBest loss: 0.328711\tAccuracy: 51.13%\n",
      "29\tValidation loss: 317.065582\tBest loss: 0.328711\tAccuracy: 58.48%\n",
      "30\tValidation loss: 297.735199\tBest loss: 0.328711\tAccuracy: 56.88%\n",
      "31\tValidation loss: 473.699951\tBest loss: 0.328711\tAccuracy: 56.45%\n",
      "32\tValidation loss: 245.989059\tBest loss: 0.328711\tAccuracy: 58.95%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, learning_rate=0.05, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1a16fccf28>, total=  55.8s\n",
      "[CV] n_neurons=70, learning_rate=0.1, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1a16fe6378> \n",
      "0\tValidation loss: 136.882751\tBest loss: 136.882751\tAccuracy: 51.49%\n",
      "1\tValidation loss: 14.238743\tBest loss: 14.238743\tAccuracy: 75.10%\n",
      "2\tValidation loss: 51.954304\tBest loss: 14.238743\tAccuracy: 70.21%\n",
      "3\tValidation loss: 8.644927\tBest loss: 8.644927\tAccuracy: 86.12%\n",
      "4\tValidation loss: 9.222609\tBest loss: 8.644927\tAccuracy: 88.43%\n",
      "5\tValidation loss: 7.051594\tBest loss: 7.051594\tAccuracy: 88.55%\n",
      "6\tValidation loss: 3.341737\tBest loss: 3.341737\tAccuracy: 92.14%\n",
      "7\tValidation loss: 17.176895\tBest loss: 3.341737\tAccuracy: 87.26%\n",
      "8\tValidation loss: 18792566.000000\tBest loss: 3.341737\tAccuracy: 36.67%\n",
      "9\tValidation loss: 54064.289062\tBest loss: 3.341737\tAccuracy: 91.56%\n",
      "10\tValidation loss: 45921.507812\tBest loss: 3.341737\tAccuracy: 91.67%\n",
      "11\tValidation loss: 18338.724609\tBest loss: 3.341737\tAccuracy: 94.80%\n",
      "12\tValidation loss: 26144.597656\tBest loss: 3.341737\tAccuracy: 91.67%\n",
      "13\tValidation loss: 34116.695312\tBest loss: 3.341737\tAccuracy: 92.06%\n",
      "14\tValidation loss: 10597.680664\tBest loss: 3.341737\tAccuracy: 94.80%\n",
      "15\tValidation loss: 25216.644531\tBest loss: 3.341737\tAccuracy: 90.62%\n",
      "16\tValidation loss: 7127.390137\tBest loss: 3.341737\tAccuracy: 96.05%\n",
      "17\tValidation loss: 10259.923828\tBest loss: 3.341737\tAccuracy: 94.41%\n",
      "18\tValidation loss: 5809.365234\tBest loss: 3.341737\tAccuracy: 95.82%\n",
      "19\tValidation loss: 6112.267578\tBest loss: 3.341737\tAccuracy: 94.72%\n",
      "20\tValidation loss: 23362.529297\tBest loss: 3.341737\tAccuracy: 92.06%\n",
      "21\tValidation loss: 9525.574219\tBest loss: 3.341737\tAccuracy: 95.74%\n",
      "22\tValidation loss: 3727.369873\tBest loss: 3.341737\tAccuracy: 95.82%\n",
      "23\tValidation loss: 8005.760742\tBest loss: 3.341737\tAccuracy: 94.76%\n",
      "24\tValidation loss: 51316.222656\tBest loss: 3.341737\tAccuracy: 84.75%\n",
      "25\tValidation loss: 5681.950195\tBest loss: 3.341737\tAccuracy: 95.58%\n",
      "26\tValidation loss: 3041.526123\tBest loss: 3.341737\tAccuracy: 95.47%\n",
      "27\tValidation loss: 2459.007324\tBest loss: 3.341737\tAccuracy: 95.19%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, learning_rate=0.1, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1a16fe6378>, total=  40.6s\n",
      "[CV] n_neurons=70, learning_rate=0.1, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1a16fe6378> \n",
      "0\tValidation loss: 903.792786\tBest loss: 903.792786\tAccuracy: 87.61%\n",
      "1\tValidation loss: 306.050323\tBest loss: 306.050323\tAccuracy: 90.30%\n",
      "2\tValidation loss: 506.760010\tBest loss: 306.050323\tAccuracy: 80.88%\n",
      "3\tValidation loss: 221.754807\tBest loss: 221.754807\tAccuracy: 91.01%\n",
      "4\tValidation loss: 125.217690\tBest loss: 125.217690\tAccuracy: 94.10%\n",
      "5\tValidation loss: 100.716995\tBest loss: 100.716995\tAccuracy: 94.72%\n",
      "6\tValidation loss: 277.744843\tBest loss: 100.716995\tAccuracy: 90.19%\n",
      "7\tValidation loss: 116.952637\tBest loss: 100.716995\tAccuracy: 93.04%\n",
      "8\tValidation loss: 212.281174\tBest loss: 100.716995\tAccuracy: 89.29%\n",
      "9\tValidation loss: 125.738800\tBest loss: 100.716995\tAccuracy: 94.45%\n",
      "10\tValidation loss: 38.618954\tBest loss: 38.618954\tAccuracy: 96.01%\n",
      "11\tValidation loss: 22.063108\tBest loss: 22.063108\tAccuracy: 96.40%\n",
      "12\tValidation loss: 42.503910\tBest loss: 22.063108\tAccuracy: 95.00%\n",
      "13\tValidation loss: 29.345461\tBest loss: 22.063108\tAccuracy: 95.82%\n",
      "14\tValidation loss: 46.292641\tBest loss: 22.063108\tAccuracy: 95.39%\n",
      "15\tValidation loss: 6068046.000000\tBest loss: 22.063108\tAccuracy: 50.59%\n",
      "16\tValidation loss: 60703.898438\tBest loss: 22.063108\tAccuracy: 94.02%\n",
      "17\tValidation loss: 40673.464844\tBest loss: 22.063108\tAccuracy: 95.23%\n",
      "18\tValidation loss: 22751.753906\tBest loss: 22.063108\tAccuracy: 95.86%\n",
      "19\tValidation loss: 20029.705078\tBest loss: 22.063108\tAccuracy: 95.47%\n",
      "20\tValidation loss: 23547.283203\tBest loss: 22.063108\tAccuracy: 95.47%\n",
      "21\tValidation loss: 18962.263672\tBest loss: 22.063108\tAccuracy: 95.39%\n",
      "22\tValidation loss: 55810.320312\tBest loss: 22.063108\tAccuracy: 93.86%\n",
      "23\tValidation loss: 40545.703125\tBest loss: 22.063108\tAccuracy: 92.69%\n",
      "24\tValidation loss: 11227.853516\tBest loss: 22.063108\tAccuracy: 96.83%\n",
      "25\tValidation loss: 30408.568359\tBest loss: 22.063108\tAccuracy: 81.67%\n",
      "26\tValidation loss: 37926.941406\tBest loss: 22.063108\tAccuracy: 90.85%\n",
      "27\tValidation loss: 8367.500000\tBest loss: 22.063108\tAccuracy: 94.96%\n",
      "28\tValidation loss: 11405.711914\tBest loss: 22.063108\tAccuracy: 96.01%\n",
      "29\tValidation loss: 13923.412109\tBest loss: 22.063108\tAccuracy: 90.73%\n",
      "30\tValidation loss: 1210436.500000\tBest loss: 22.063108\tAccuracy: 87.22%\n",
      "31\tValidation loss: 142597.390625\tBest loss: 22.063108\tAccuracy: 95.93%\n",
      "32\tValidation loss: 182371.531250\tBest loss: 22.063108\tAccuracy: 96.36%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, learning_rate=0.1, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1a16fe6378>, total=  47.3s\n",
      "[CV] n_neurons=70, learning_rate=0.1, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1a16fe6378> \n",
      "0\tValidation loss: 77.390137\tBest loss: 77.390137\tAccuracy: 93.90%\n",
      "1\tValidation loss: 17.145906\tBest loss: 17.145906\tAccuracy: 95.62%\n",
      "2\tValidation loss: 18.487823\tBest loss: 17.145906\tAccuracy: 96.25%\n",
      "3\tValidation loss: 14.010352\tBest loss: 14.010352\tAccuracy: 95.78%\n",
      "4\tValidation loss: 9.331843\tBest loss: 9.331843\tAccuracy: 95.74%\n",
      "5\tValidation loss: 8.538023\tBest loss: 8.538023\tAccuracy: 95.86%\n",
      "6\tValidation loss: 65.466049\tBest loss: 8.538023\tAccuracy: 87.10%\n",
      "7\tValidation loss: 2110724.000000\tBest loss: 8.538023\tAccuracy: 21.81%\n",
      "8\tValidation loss: 105289.523438\tBest loss: 8.538023\tAccuracy: 69.55%\n",
      "9\tValidation loss: 58646.230469\tBest loss: 8.538023\tAccuracy: 80.41%\n",
      "10\tValidation loss: 51370.976562\tBest loss: 8.538023\tAccuracy: 83.82%\n",
      "11\tValidation loss: 23006.568359\tBest loss: 8.538023\tAccuracy: 90.03%\n",
      "12\tValidation loss: 40425.230469\tBest loss: 8.538023\tAccuracy: 87.37%\n",
      "13\tValidation loss: 31937.949219\tBest loss: 8.538023\tAccuracy: 90.46%\n",
      "14\tValidation loss: 15928.384766\tBest loss: 8.538023\tAccuracy: 93.43%\n",
      "15\tValidation loss: 10631.873047\tBest loss: 8.538023\tAccuracy: 94.72%\n",
      "16\tValidation loss: 18595.140625\tBest loss: 8.538023\tAccuracy: 92.81%\n",
      "17\tValidation loss: 17244.125000\tBest loss: 8.538023\tAccuracy: 93.00%\n",
      "18\tValidation loss: 17504.246094\tBest loss: 8.538023\tAccuracy: 93.24%\n",
      "19\tValidation loss: 10378.546875\tBest loss: 8.538023\tAccuracy: 93.55%\n",
      "20\tValidation loss: 249216.906250\tBest loss: 8.538023\tAccuracy: 67.55%\n",
      "21\tValidation loss: 49510.472656\tBest loss: 8.538023\tAccuracy: 80.88%\n",
      "22\tValidation loss: 9346.694336\tBest loss: 8.538023\tAccuracy: 96.13%\n",
      "23\tValidation loss: 23541.728516\tBest loss: 8.538023\tAccuracy: 91.83%\n",
      "24\tValidation loss: 11257.556641\tBest loss: 8.538023\tAccuracy: 92.89%\n",
      "25\tValidation loss: 446457.593750\tBest loss: 8.538023\tAccuracy: 91.36%\n",
      "26\tValidation loss: 44554.125000\tBest loss: 8.538023\tAccuracy: 93.35%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, learning_rate=0.1, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1a16fe6378>, total=  38.5s\n",
      "[CV] n_neurons=120, learning_rate=0.01, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1a16fccf28> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.109893\tBest loss: 0.109893\tAccuracy: 96.76%\n",
      "1\tValidation loss: 0.069199\tBest loss: 0.069199\tAccuracy: 98.12%\n",
      "2\tValidation loss: 0.069521\tBest loss: 0.069199\tAccuracy: 97.93%\n",
      "3\tValidation loss: 0.052694\tBest loss: 0.052694\tAccuracy: 98.32%\n",
      "4\tValidation loss: 0.059152\tBest loss: 0.052694\tAccuracy: 98.20%\n",
      "5\tValidation loss: 0.051254\tBest loss: 0.051254\tAccuracy: 98.51%\n",
      "6\tValidation loss: 0.055154\tBest loss: 0.051254\tAccuracy: 98.59%\n",
      "7\tValidation loss: 0.080139\tBest loss: 0.051254\tAccuracy: 98.05%\n",
      "8\tValidation loss: 0.069264\tBest loss: 0.051254\tAccuracy: 98.24%\n",
      "9\tValidation loss: 0.055425\tBest loss: 0.051254\tAccuracy: 98.67%\n",
      "10\tValidation loss: 0.060814\tBest loss: 0.051254\tAccuracy: 98.51%\n",
      "11\tValidation loss: 0.047053\tBest loss: 0.047053\tAccuracy: 98.87%\n",
      "12\tValidation loss: 0.065596\tBest loss: 0.047053\tAccuracy: 98.67%\n",
      "13\tValidation loss: 0.091969\tBest loss: 0.047053\tAccuracy: 97.93%\n",
      "14\tValidation loss: 0.067328\tBest loss: 0.047053\tAccuracy: 98.51%\n",
      "15\tValidation loss: 0.058094\tBest loss: 0.047053\tAccuracy: 98.63%\n",
      "16\tValidation loss: 0.062247\tBest loss: 0.047053\tAccuracy: 98.83%\n",
      "17\tValidation loss: 0.066149\tBest loss: 0.047053\tAccuracy: 98.71%\n",
      "18\tValidation loss: 0.064459\tBest loss: 0.047053\tAccuracy: 98.67%\n",
      "19\tValidation loss: 0.066063\tBest loss: 0.047053\tAccuracy: 98.83%\n",
      "20\tValidation loss: 0.061386\tBest loss: 0.047053\tAccuracy: 98.83%\n",
      "21\tValidation loss: 0.079144\tBest loss: 0.047053\tAccuracy: 98.63%\n",
      "22\tValidation loss: 0.082135\tBest loss: 0.047053\tAccuracy: 98.67%\n",
      "23\tValidation loss: 0.074450\tBest loss: 0.047053\tAccuracy: 98.51%\n",
      "24\tValidation loss: 0.061638\tBest loss: 0.047053\tAccuracy: 98.71%\n",
      "25\tValidation loss: 0.067002\tBest loss: 0.047053\tAccuracy: 98.94%\n",
      "26\tValidation loss: 0.060088\tBest loss: 0.047053\tAccuracy: 98.94%\n",
      "27\tValidation loss: 0.061756\tBest loss: 0.047053\tAccuracy: 98.75%\n",
      "28\tValidation loss: 0.068485\tBest loss: 0.047053\tAccuracy: 98.83%\n",
      "29\tValidation loss: 0.097081\tBest loss: 0.047053\tAccuracy: 98.40%\n",
      "30\tValidation loss: 0.059427\tBest loss: 0.047053\tAccuracy: 98.79%\n",
      "31\tValidation loss: 0.064735\tBest loss: 0.047053\tAccuracy: 98.94%\n",
      "32\tValidation loss: 0.083422\tBest loss: 0.047053\tAccuracy: 98.75%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, learning_rate=0.01, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1a16fccf28>, total=  26.2s\n",
      "[CV] n_neurons=120, learning_rate=0.01, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1a16fccf28> \n",
      "0\tValidation loss: 0.123812\tBest loss: 0.123812\tAccuracy: 95.93%\n",
      "1\tValidation loss: 0.080257\tBest loss: 0.080257\tAccuracy: 97.73%\n",
      "2\tValidation loss: 0.066383\tBest loss: 0.066383\tAccuracy: 97.89%\n",
      "3\tValidation loss: 0.058967\tBest loss: 0.058967\tAccuracy: 98.12%\n",
      "4\tValidation loss: 0.068581\tBest loss: 0.058967\tAccuracy: 98.16%\n",
      "5\tValidation loss: 0.057580\tBest loss: 0.057580\tAccuracy: 98.28%\n",
      "6\tValidation loss: 0.057220\tBest loss: 0.057220\tAccuracy: 98.71%\n",
      "7\tValidation loss: 0.062214\tBest loss: 0.057220\tAccuracy: 98.28%\n",
      "8\tValidation loss: 0.039217\tBest loss: 0.039217\tAccuracy: 98.83%\n",
      "9\tValidation loss: 0.058301\tBest loss: 0.039217\tAccuracy: 98.91%\n",
      "10\tValidation loss: 0.043502\tBest loss: 0.039217\tAccuracy: 98.71%\n",
      "11\tValidation loss: 0.056498\tBest loss: 0.039217\tAccuracy: 98.91%\n",
      "12\tValidation loss: 0.055805\tBest loss: 0.039217\tAccuracy: 98.75%\n",
      "13\tValidation loss: 0.063670\tBest loss: 0.039217\tAccuracy: 98.87%\n",
      "14\tValidation loss: 0.058458\tBest loss: 0.039217\tAccuracy: 98.75%\n",
      "15\tValidation loss: 0.048836\tBest loss: 0.039217\tAccuracy: 98.75%\n",
      "16\tValidation loss: 0.049244\tBest loss: 0.039217\tAccuracy: 98.83%\n",
      "17\tValidation loss: 0.068090\tBest loss: 0.039217\tAccuracy: 98.75%\n",
      "18\tValidation loss: 0.067429\tBest loss: 0.039217\tAccuracy: 98.79%\n",
      "19\tValidation loss: 0.057214\tBest loss: 0.039217\tAccuracy: 98.79%\n",
      "20\tValidation loss: 0.058164\tBest loss: 0.039217\tAccuracy: 98.79%\n",
      "21\tValidation loss: 0.060888\tBest loss: 0.039217\tAccuracy: 98.71%\n",
      "22\tValidation loss: 0.065185\tBest loss: 0.039217\tAccuracy: 98.71%\n",
      "23\tValidation loss: 0.055923\tBest loss: 0.039217\tAccuracy: 98.98%\n",
      "24\tValidation loss: 0.073616\tBest loss: 0.039217\tAccuracy: 98.48%\n",
      "25\tValidation loss: 0.045103\tBest loss: 0.039217\tAccuracy: 98.98%\n",
      "26\tValidation loss: 0.062515\tBest loss: 0.039217\tAccuracy: 98.87%\n",
      "27\tValidation loss: 0.054340\tBest loss: 0.039217\tAccuracy: 98.79%\n",
      "28\tValidation loss: 0.076641\tBest loss: 0.039217\tAccuracy: 98.51%\n",
      "29\tValidation loss: 0.068903\tBest loss: 0.039217\tAccuracy: 98.71%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, learning_rate=0.01, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1a16fccf28>, total=  24.4s\n",
      "[CV] n_neurons=120, learning_rate=0.01, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1a16fccf28> \n",
      "0\tValidation loss: 0.106846\tBest loss: 0.106846\tAccuracy: 96.95%\n",
      "1\tValidation loss: 0.072875\tBest loss: 0.072875\tAccuracy: 97.89%\n",
      "2\tValidation loss: 0.061414\tBest loss: 0.061414\tAccuracy: 98.05%\n",
      "3\tValidation loss: 0.058316\tBest loss: 0.058316\tAccuracy: 98.16%\n",
      "4\tValidation loss: 0.055374\tBest loss: 0.055374\tAccuracy: 98.24%\n",
      "5\tValidation loss: 0.058589\tBest loss: 0.055374\tAccuracy: 98.44%\n",
      "6\tValidation loss: 0.056207\tBest loss: 0.055374\tAccuracy: 98.55%\n",
      "7\tValidation loss: 0.053679\tBest loss: 0.053679\tAccuracy: 98.55%\n",
      "8\tValidation loss: 0.070739\tBest loss: 0.053679\tAccuracy: 98.59%\n",
      "9\tValidation loss: 0.069450\tBest loss: 0.053679\tAccuracy: 98.63%\n",
      "10\tValidation loss: 0.086138\tBest loss: 0.053679\tAccuracy: 98.51%\n",
      "11\tValidation loss: 0.061586\tBest loss: 0.053679\tAccuracy: 98.71%\n",
      "12\tValidation loss: 0.075429\tBest loss: 0.053679\tAccuracy: 98.67%\n",
      "13\tValidation loss: 0.072186\tBest loss: 0.053679\tAccuracy: 98.71%\n",
      "14\tValidation loss: 0.081433\tBest loss: 0.053679\tAccuracy: 98.55%\n",
      "15\tValidation loss: 0.048292\tBest loss: 0.048292\tAccuracy: 98.71%\n",
      "16\tValidation loss: 0.062978\tBest loss: 0.048292\tAccuracy: 98.71%\n",
      "17\tValidation loss: 0.069370\tBest loss: 0.048292\tAccuracy: 98.83%\n",
      "18\tValidation loss: 0.052099\tBest loss: 0.048292\tAccuracy: 98.94%\n",
      "19\tValidation loss: 0.059133\tBest loss: 0.048292\tAccuracy: 98.91%\n",
      "20\tValidation loss: 0.072558\tBest loss: 0.048292\tAccuracy: 98.83%\n",
      "21\tValidation loss: 0.062465\tBest loss: 0.048292\tAccuracy: 98.75%\n",
      "22\tValidation loss: 0.065369\tBest loss: 0.048292\tAccuracy: 99.10%\n",
      "23\tValidation loss: 0.050582\tBest loss: 0.048292\tAccuracy: 98.79%\n",
      "24\tValidation loss: 0.056830\tBest loss: 0.048292\tAccuracy: 98.87%\n",
      "25\tValidation loss: 0.057296\tBest loss: 0.048292\tAccuracy: 99.06%\n",
      "26\tValidation loss: 0.054760\tBest loss: 0.048292\tAccuracy: 99.14%\n",
      "27\tValidation loss: 0.056548\tBest loss: 0.048292\tAccuracy: 98.71%\n",
      "28\tValidation loss: 0.126581\tBest loss: 0.048292\tAccuracy: 98.59%\n",
      "29\tValidation loss: 0.052667\tBest loss: 0.048292\tAccuracy: 99.10%\n",
      "30\tValidation loss: 0.074649\tBest loss: 0.048292\tAccuracy: 99.10%\n",
      "31\tValidation loss: 0.072161\tBest loss: 0.048292\tAccuracy: 99.02%\n",
      "32\tValidation loss: 0.081623\tBest loss: 0.048292\tAccuracy: 98.59%\n",
      "33\tValidation loss: 0.085156\tBest loss: 0.048292\tAccuracy: 98.83%\n",
      "34\tValidation loss: 0.071461\tBest loss: 0.048292\tAccuracy: 98.59%\n",
      "35\tValidation loss: 0.079087\tBest loss: 0.048292\tAccuracy: 98.83%\n",
      "36\tValidation loss: 0.089424\tBest loss: 0.048292\tAccuracy: 99.02%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, learning_rate=0.01, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1a16fccf28>, total=  32.0s\n",
      "[CV] n_neurons=90, learning_rate=0.01, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1a16fccf28> \n",
      "0\tValidation loss: 0.104860\tBest loss: 0.104860\tAccuracy: 96.83%\n",
      "1\tValidation loss: 0.063637\tBest loss: 0.063637\tAccuracy: 98.01%\n",
      "2\tValidation loss: 0.056582\tBest loss: 0.056582\tAccuracy: 98.16%\n",
      "3\tValidation loss: 0.075052\tBest loss: 0.056582\tAccuracy: 98.05%\n",
      "4\tValidation loss: 0.060172\tBest loss: 0.056582\tAccuracy: 97.93%\n",
      "5\tValidation loss: 0.046366\tBest loss: 0.046366\tAccuracy: 98.55%\n",
      "6\tValidation loss: 0.045189\tBest loss: 0.045189\tAccuracy: 98.67%\n",
      "7\tValidation loss: 0.061849\tBest loss: 0.045189\tAccuracy: 98.67%\n",
      "8\tValidation loss: 0.043865\tBest loss: 0.043865\tAccuracy: 98.79%\n",
      "9\tValidation loss: 0.050181\tBest loss: 0.043865\tAccuracy: 98.59%\n",
      "10\tValidation loss: 0.057381\tBest loss: 0.043865\tAccuracy: 98.59%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\tValidation loss: 0.070314\tBest loss: 0.043865\tAccuracy: 98.32%\n",
      "12\tValidation loss: 0.055357\tBest loss: 0.043865\tAccuracy: 98.63%\n",
      "13\tValidation loss: 0.042599\tBest loss: 0.042599\tAccuracy: 99.06%\n",
      "14\tValidation loss: 0.064410\tBest loss: 0.042599\tAccuracy: 98.75%\n",
      "15\tValidation loss: 0.051728\tBest loss: 0.042599\tAccuracy: 98.79%\n",
      "16\tValidation loss: 0.053933\tBest loss: 0.042599\tAccuracy: 98.59%\n",
      "17\tValidation loss: 0.062257\tBest loss: 0.042599\tAccuracy: 98.63%\n",
      "18\tValidation loss: 0.052563\tBest loss: 0.042599\tAccuracy: 98.83%\n",
      "19\tValidation loss: 0.070491\tBest loss: 0.042599\tAccuracy: 98.51%\n",
      "20\tValidation loss: 0.060236\tBest loss: 0.042599\tAccuracy: 98.83%\n",
      "21\tValidation loss: 0.059361\tBest loss: 0.042599\tAccuracy: 98.94%\n",
      "22\tValidation loss: 0.076154\tBest loss: 0.042599\tAccuracy: 98.48%\n",
      "23\tValidation loss: 0.029685\tBest loss: 0.029685\tAccuracy: 99.14%\n",
      "24\tValidation loss: 0.039523\tBest loss: 0.029685\tAccuracy: 99.10%\n",
      "25\tValidation loss: 0.051737\tBest loss: 0.029685\tAccuracy: 98.63%\n",
      "26\tValidation loss: 0.059735\tBest loss: 0.029685\tAccuracy: 98.51%\n",
      "27\tValidation loss: 0.039157\tBest loss: 0.029685\tAccuracy: 99.10%\n",
      "28\tValidation loss: 0.042404\tBest loss: 0.029685\tAccuracy: 99.10%\n",
      "29\tValidation loss: 0.037423\tBest loss: 0.029685\tAccuracy: 99.18%\n",
      "30\tValidation loss: 0.038583\tBest loss: 0.029685\tAccuracy: 99.22%\n",
      "31\tValidation loss: 0.037931\tBest loss: 0.029685\tAccuracy: 99.22%\n",
      "32\tValidation loss: 0.058953\tBest loss: 0.029685\tAccuracy: 98.87%\n",
      "33\tValidation loss: 0.054270\tBest loss: 0.029685\tAccuracy: 98.98%\n",
      "34\tValidation loss: 0.049007\tBest loss: 0.029685\tAccuracy: 98.94%\n",
      "35\tValidation loss: 0.050768\tBest loss: 0.029685\tAccuracy: 99.10%\n",
      "36\tValidation loss: 0.054600\tBest loss: 0.029685\tAccuracy: 99.02%\n",
      "37\tValidation loss: 0.056486\tBest loss: 0.029685\tAccuracy: 99.02%\n",
      "38\tValidation loss: 0.056774\tBest loss: 0.029685\tAccuracy: 99.02%\n",
      "39\tValidation loss: 0.057176\tBest loss: 0.029685\tAccuracy: 99.02%\n",
      "40\tValidation loss: 0.057835\tBest loss: 0.029685\tAccuracy: 99.02%\n",
      "41\tValidation loss: 0.058364\tBest loss: 0.029685\tAccuracy: 99.02%\n",
      "42\tValidation loss: 0.058962\tBest loss: 0.029685\tAccuracy: 99.02%\n",
      "43\tValidation loss: 0.059350\tBest loss: 0.029685\tAccuracy: 99.02%\n",
      "44\tValidation loss: 0.059861\tBest loss: 0.029685\tAccuracy: 99.06%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, learning_rate=0.01, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1a16fccf28>, total=  32.4s\n",
      "[CV] n_neurons=90, learning_rate=0.01, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1a16fccf28> \n",
      "0\tValidation loss: 0.097192\tBest loss: 0.097192\tAccuracy: 96.56%\n",
      "1\tValidation loss: 0.063450\tBest loss: 0.063450\tAccuracy: 97.93%\n",
      "2\tValidation loss: 0.062934\tBest loss: 0.062934\tAccuracy: 97.93%\n",
      "3\tValidation loss: 0.065371\tBest loss: 0.062934\tAccuracy: 98.05%\n",
      "4\tValidation loss: 0.067181\tBest loss: 0.062934\tAccuracy: 98.32%\n",
      "5\tValidation loss: 0.069233\tBest loss: 0.062934\tAccuracy: 97.97%\n",
      "6\tValidation loss: 0.064449\tBest loss: 0.062934\tAccuracy: 98.32%\n",
      "7\tValidation loss: 0.056565\tBest loss: 0.056565\tAccuracy: 98.63%\n",
      "8\tValidation loss: 0.060483\tBest loss: 0.056565\tAccuracy: 98.20%\n",
      "9\tValidation loss: 0.052202\tBest loss: 0.052202\tAccuracy: 98.67%\n",
      "10\tValidation loss: 0.069184\tBest loss: 0.052202\tAccuracy: 98.40%\n",
      "11\tValidation loss: 0.054048\tBest loss: 0.052202\tAccuracy: 98.63%\n",
      "12\tValidation loss: 0.059035\tBest loss: 0.052202\tAccuracy: 98.40%\n",
      "13\tValidation loss: 0.052629\tBest loss: 0.052202\tAccuracy: 98.55%\n",
      "14\tValidation loss: 0.063174\tBest loss: 0.052202\tAccuracy: 98.71%\n",
      "15\tValidation loss: 0.073746\tBest loss: 0.052202\tAccuracy: 98.63%\n",
      "16\tValidation loss: 0.073330\tBest loss: 0.052202\tAccuracy: 98.48%\n",
      "17\tValidation loss: 0.064079\tBest loss: 0.052202\tAccuracy: 98.75%\n",
      "18\tValidation loss: 0.061917\tBest loss: 0.052202\tAccuracy: 98.63%\n",
      "19\tValidation loss: 0.063638\tBest loss: 0.052202\tAccuracy: 98.63%\n",
      "20\tValidation loss: 0.069333\tBest loss: 0.052202\tAccuracy: 98.44%\n",
      "21\tValidation loss: 0.070345\tBest loss: 0.052202\tAccuracy: 98.59%\n",
      "22\tValidation loss: 0.075301\tBest loss: 0.052202\tAccuracy: 98.75%\n",
      "23\tValidation loss: 0.072748\tBest loss: 0.052202\tAccuracy: 98.79%\n",
      "24\tValidation loss: 0.060565\tBest loss: 0.052202\tAccuracy: 98.67%\n",
      "25\tValidation loss: 0.079969\tBest loss: 0.052202\tAccuracy: 98.63%\n",
      "26\tValidation loss: 0.080765\tBest loss: 0.052202\tAccuracy: 98.63%\n",
      "27\tValidation loss: 0.086176\tBest loss: 0.052202\tAccuracy: 98.32%\n",
      "28\tValidation loss: 0.095212\tBest loss: 0.052202\tAccuracy: 98.48%\n",
      "29\tValidation loss: 0.064402\tBest loss: 0.052202\tAccuracy: 98.94%\n",
      "30\tValidation loss: 0.089429\tBest loss: 0.052202\tAccuracy: 98.48%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, learning_rate=0.01, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1a16fccf28>, total=  22.1s\n",
      "[CV] n_neurons=90, learning_rate=0.01, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1a16fccf28> \n",
      "0\tValidation loss: 0.081408\tBest loss: 0.081408\tAccuracy: 97.54%\n",
      "1\tValidation loss: 0.070396\tBest loss: 0.070396\tAccuracy: 98.01%\n",
      "2\tValidation loss: 0.065585\tBest loss: 0.065585\tAccuracy: 97.97%\n",
      "3\tValidation loss: 0.068603\tBest loss: 0.065585\tAccuracy: 97.97%\n",
      "4\tValidation loss: 0.049520\tBest loss: 0.049520\tAccuracy: 98.24%\n",
      "5\tValidation loss: 0.048798\tBest loss: 0.048798\tAccuracy: 98.36%\n",
      "6\tValidation loss: 0.073533\tBest loss: 0.048798\tAccuracy: 98.08%\n",
      "7\tValidation loss: 0.055059\tBest loss: 0.048798\tAccuracy: 98.20%\n",
      "8\tValidation loss: 0.081981\tBest loss: 0.048798\tAccuracy: 98.12%\n",
      "9\tValidation loss: 0.053733\tBest loss: 0.048798\tAccuracy: 98.75%\n",
      "10\tValidation loss: 0.047974\tBest loss: 0.047974\tAccuracy: 98.75%\n",
      "11\tValidation loss: 0.073118\tBest loss: 0.047974\tAccuracy: 98.48%\n",
      "12\tValidation loss: 0.064895\tBest loss: 0.047974\tAccuracy: 98.40%\n",
      "13\tValidation loss: 0.057934\tBest loss: 0.047974\tAccuracy: 98.59%\n",
      "14\tValidation loss: 0.063307\tBest loss: 0.047974\tAccuracy: 98.59%\n",
      "15\tValidation loss: 0.095427\tBest loss: 0.047974\tAccuracy: 98.12%\n",
      "16\tValidation loss: 0.076144\tBest loss: 0.047974\tAccuracy: 98.75%\n",
      "17\tValidation loss: 0.073293\tBest loss: 0.047974\tAccuracy: 98.48%\n",
      "18\tValidation loss: 0.071305\tBest loss: 0.047974\tAccuracy: 98.79%\n",
      "19\tValidation loss: 0.082047\tBest loss: 0.047974\tAccuracy: 98.59%\n",
      "20\tValidation loss: 0.069600\tBest loss: 0.047974\tAccuracy: 98.79%\n",
      "21\tValidation loss: 0.075337\tBest loss: 0.047974\tAccuracy: 98.44%\n",
      "22\tValidation loss: 0.081452\tBest loss: 0.047974\tAccuracy: 98.44%\n",
      "23\tValidation loss: 0.119117\tBest loss: 0.047974\tAccuracy: 98.20%\n",
      "24\tValidation loss: 0.070382\tBest loss: 0.047974\tAccuracy: 98.71%\n",
      "25\tValidation loss: 0.081878\tBest loss: 0.047974\tAccuracy: 98.51%\n",
      "26\tValidation loss: 0.088433\tBest loss: 0.047974\tAccuracy: 98.55%\n",
      "27\tValidation loss: 0.090895\tBest loss: 0.047974\tAccuracy: 98.75%\n",
      "28\tValidation loss: 0.090187\tBest loss: 0.047974\tAccuracy: 98.48%\n",
      "29\tValidation loss: 0.066832\tBest loss: 0.047974\tAccuracy: 98.79%\n",
      "30\tValidation loss: 0.063379\tBest loss: 0.047974\tAccuracy: 98.83%\n",
      "31\tValidation loss: 0.136788\tBest loss: 0.047974\tAccuracy: 98.08%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, learning_rate=0.01, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1a16fccf28>, total=  19.7s\n",
      "[CV] n_neurons=140, learning_rate=0.01, batch_size=500, activation=<function elu at 0x1099692f0> \n",
      "0\tValidation loss: 0.140913\tBest loss: 0.140913\tAccuracy: 95.39%\n",
      "1\tValidation loss: 0.082842\tBest loss: 0.082842\tAccuracy: 97.62%\n",
      "2\tValidation loss: 0.086206\tBest loss: 0.082842\tAccuracy: 97.38%\n",
      "3\tValidation loss: 0.073511\tBest loss: 0.073511\tAccuracy: 97.54%\n",
      "4\tValidation loss: 0.062357\tBest loss: 0.062357\tAccuracy: 98.05%\n",
      "5\tValidation loss: 0.055234\tBest loss: 0.055234\tAccuracy: 98.36%\n",
      "6\tValidation loss: 0.058128\tBest loss: 0.055234\tAccuracy: 98.28%\n",
      "7\tValidation loss: 0.058523\tBest loss: 0.055234\tAccuracy: 98.36%\n",
      "8\tValidation loss: 0.072046\tBest loss: 0.055234\tAccuracy: 98.05%\n",
      "9\tValidation loss: 0.060190\tBest loss: 0.055234\tAccuracy: 98.32%\n",
      "10\tValidation loss: 0.060072\tBest loss: 0.055234\tAccuracy: 98.44%\n",
      "11\tValidation loss: 0.059317\tBest loss: 0.055234\tAccuracy: 98.59%\n",
      "12\tValidation loss: 0.067150\tBest loss: 0.055234\tAccuracy: 98.48%\n",
      "13\tValidation loss: 0.088320\tBest loss: 0.055234\tAccuracy: 97.85%\n",
      "14\tValidation loss: 0.056568\tBest loss: 0.055234\tAccuracy: 98.59%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\tValidation loss: 0.074958\tBest loss: 0.055234\tAccuracy: 98.51%\n",
      "16\tValidation loss: 0.061288\tBest loss: 0.055234\tAccuracy: 98.79%\n",
      "17\tValidation loss: 0.078039\tBest loss: 0.055234\tAccuracy: 98.32%\n",
      "18\tValidation loss: 0.071433\tBest loss: 0.055234\tAccuracy: 98.48%\n",
      "19\tValidation loss: 0.074246\tBest loss: 0.055234\tAccuracy: 98.40%\n",
      "20\tValidation loss: 0.068495\tBest loss: 0.055234\tAccuracy: 98.71%\n",
      "21\tValidation loss: 0.054553\tBest loss: 0.054553\tAccuracy: 98.59%\n",
      "22\tValidation loss: 0.065967\tBest loss: 0.054553\tAccuracy: 98.55%\n",
      "23\tValidation loss: 0.062534\tBest loss: 0.054553\tAccuracy: 98.79%\n",
      "24\tValidation loss: 0.059071\tBest loss: 0.054553\tAccuracy: 98.67%\n",
      "25\tValidation loss: 0.078951\tBest loss: 0.054553\tAccuracy: 98.20%\n",
      "26\tValidation loss: 0.070349\tBest loss: 0.054553\tAccuracy: 98.28%\n",
      "27\tValidation loss: 0.060198\tBest loss: 0.054553\tAccuracy: 98.75%\n",
      "28\tValidation loss: 0.068352\tBest loss: 0.054553\tAccuracy: 98.75%\n",
      "29\tValidation loss: 0.069762\tBest loss: 0.054553\tAccuracy: 98.71%\n",
      "30\tValidation loss: 0.068036\tBest loss: 0.054553\tAccuracy: 98.71%\n",
      "31\tValidation loss: 0.075562\tBest loss: 0.054553\tAccuracy: 98.83%\n",
      "32\tValidation loss: 0.067137\tBest loss: 0.054553\tAccuracy: 98.83%\n",
      "33\tValidation loss: 0.076320\tBest loss: 0.054553\tAccuracy: 98.83%\n",
      "34\tValidation loss: 0.079266\tBest loss: 0.054553\tAccuracy: 98.75%\n",
      "35\tValidation loss: 0.076949\tBest loss: 0.054553\tAccuracy: 98.91%\n",
      "36\tValidation loss: 0.089416\tBest loss: 0.054553\tAccuracy: 98.67%\n",
      "37\tValidation loss: 0.065223\tBest loss: 0.054553\tAccuracy: 98.36%\n",
      "38\tValidation loss: 0.080211\tBest loss: 0.054553\tAccuracy: 98.20%\n",
      "39\tValidation loss: 0.066022\tBest loss: 0.054553\tAccuracy: 98.36%\n",
      "40\tValidation loss: 0.062103\tBest loss: 0.054553\tAccuracy: 98.87%\n",
      "41\tValidation loss: 0.068659\tBest loss: 0.054553\tAccuracy: 98.67%\n",
      "42\tValidation loss: 0.070367\tBest loss: 0.054553\tAccuracy: 98.83%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, learning_rate=0.01, batch_size=500, activation=<function elu at 0x1099692f0>, total=  38.1s\n",
      "[CV] n_neurons=140, learning_rate=0.01, batch_size=500, activation=<function elu at 0x1099692f0> \n",
      "0\tValidation loss: 0.127973\tBest loss: 0.127973\tAccuracy: 95.93%\n",
      "1\tValidation loss: 0.076743\tBest loss: 0.076743\tAccuracy: 97.73%\n",
      "2\tValidation loss: 0.059686\tBest loss: 0.059686\tAccuracy: 98.16%\n",
      "3\tValidation loss: 0.055501\tBest loss: 0.055501\tAccuracy: 98.40%\n",
      "4\tValidation loss: 0.049846\tBest loss: 0.049846\tAccuracy: 98.36%\n",
      "5\tValidation loss: 0.050811\tBest loss: 0.049846\tAccuracy: 98.44%\n",
      "6\tValidation loss: 0.036369\tBest loss: 0.036369\tAccuracy: 98.91%\n",
      "7\tValidation loss: 0.040807\tBest loss: 0.036369\tAccuracy: 98.67%\n",
      "8\tValidation loss: 0.055375\tBest loss: 0.036369\tAccuracy: 98.44%\n",
      "9\tValidation loss: 0.053493\tBest loss: 0.036369\tAccuracy: 98.48%\n",
      "10\tValidation loss: 0.054981\tBest loss: 0.036369\tAccuracy: 98.51%\n",
      "11\tValidation loss: 0.060102\tBest loss: 0.036369\tAccuracy: 98.44%\n",
      "12\tValidation loss: 0.047421\tBest loss: 0.036369\tAccuracy: 98.83%\n",
      "13\tValidation loss: 0.052848\tBest loss: 0.036369\tAccuracy: 98.83%\n",
      "14\tValidation loss: 0.053516\tBest loss: 0.036369\tAccuracy: 98.83%\n",
      "15\tValidation loss: 0.076074\tBest loss: 0.036369\tAccuracy: 98.71%\n",
      "16\tValidation loss: 0.060260\tBest loss: 0.036369\tAccuracy: 98.59%\n",
      "17\tValidation loss: 0.061834\tBest loss: 0.036369\tAccuracy: 98.75%\n",
      "18\tValidation loss: 0.069488\tBest loss: 0.036369\tAccuracy: 98.63%\n",
      "19\tValidation loss: 0.053247\tBest loss: 0.036369\tAccuracy: 98.75%\n",
      "20\tValidation loss: 0.059870\tBest loss: 0.036369\tAccuracy: 98.71%\n",
      "21\tValidation loss: 0.048789\tBest loss: 0.036369\tAccuracy: 98.83%\n",
      "22\tValidation loss: 0.057119\tBest loss: 0.036369\tAccuracy: 98.87%\n",
      "23\tValidation loss: 0.060842\tBest loss: 0.036369\tAccuracy: 98.94%\n",
      "24\tValidation loss: 0.055971\tBest loss: 0.036369\tAccuracy: 98.83%\n",
      "25\tValidation loss: 0.099411\tBest loss: 0.036369\tAccuracy: 98.59%\n",
      "26\tValidation loss: 0.076813\tBest loss: 0.036369\tAccuracy: 98.40%\n",
      "27\tValidation loss: 0.059999\tBest loss: 0.036369\tAccuracy: 98.94%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, learning_rate=0.01, batch_size=500, activation=<function elu at 0x1099692f0>, total=  25.0s\n",
      "[CV] n_neurons=140, learning_rate=0.01, batch_size=500, activation=<function elu at 0x1099692f0> \n",
      "0\tValidation loss: 0.122152\tBest loss: 0.122152\tAccuracy: 95.93%\n",
      "1\tValidation loss: 0.085570\tBest loss: 0.085570\tAccuracy: 97.03%\n",
      "2\tValidation loss: 0.070516\tBest loss: 0.070516\tAccuracy: 98.01%\n",
      "3\tValidation loss: 0.049195\tBest loss: 0.049195\tAccuracy: 98.48%\n",
      "4\tValidation loss: 0.051055\tBest loss: 0.049195\tAccuracy: 98.71%\n",
      "5\tValidation loss: 0.045651\tBest loss: 0.045651\tAccuracy: 98.55%\n",
      "6\tValidation loss: 0.050154\tBest loss: 0.045651\tAccuracy: 98.40%\n",
      "7\tValidation loss: 0.043203\tBest loss: 0.043203\tAccuracy: 98.59%\n",
      "8\tValidation loss: 0.060054\tBest loss: 0.043203\tAccuracy: 98.28%\n",
      "9\tValidation loss: 0.042503\tBest loss: 0.042503\tAccuracy: 98.94%\n",
      "10\tValidation loss: 0.054237\tBest loss: 0.042503\tAccuracy: 98.83%\n",
      "11\tValidation loss: 0.049446\tBest loss: 0.042503\tAccuracy: 98.67%\n",
      "12\tValidation loss: 0.047243\tBest loss: 0.042503\tAccuracy: 98.98%\n",
      "13\tValidation loss: 0.045299\tBest loss: 0.042503\tAccuracy: 98.83%\n",
      "14\tValidation loss: 0.077547\tBest loss: 0.042503\tAccuracy: 98.12%\n",
      "15\tValidation loss: 0.048267\tBest loss: 0.042503\tAccuracy: 98.83%\n",
      "16\tValidation loss: 0.052027\tBest loss: 0.042503\tAccuracy: 98.98%\n",
      "17\tValidation loss: 0.052052\tBest loss: 0.042503\tAccuracy: 98.91%\n",
      "18\tValidation loss: 0.047844\tBest loss: 0.042503\tAccuracy: 98.71%\n",
      "19\tValidation loss: 0.061905\tBest loss: 0.042503\tAccuracy: 98.98%\n",
      "20\tValidation loss: 0.074107\tBest loss: 0.042503\tAccuracy: 98.48%\n",
      "21\tValidation loss: 0.063293\tBest loss: 0.042503\tAccuracy: 98.71%\n",
      "22\tValidation loss: 0.062413\tBest loss: 0.042503\tAccuracy: 98.75%\n",
      "23\tValidation loss: 0.056856\tBest loss: 0.042503\tAccuracy: 98.91%\n",
      "24\tValidation loss: 0.077425\tBest loss: 0.042503\tAccuracy: 98.87%\n",
      "25\tValidation loss: 0.065078\tBest loss: 0.042503\tAccuracy: 98.75%\n",
      "26\tValidation loss: 0.049684\tBest loss: 0.042503\tAccuracy: 98.94%\n",
      "27\tValidation loss: 0.067998\tBest loss: 0.042503\tAccuracy: 98.83%\n",
      "28\tValidation loss: 0.073989\tBest loss: 0.042503\tAccuracy: 98.87%\n",
      "29\tValidation loss: 0.092299\tBest loss: 0.042503\tAccuracy: 98.32%\n",
      "30\tValidation loss: 0.043889\tBest loss: 0.042503\tAccuracy: 99.18%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, learning_rate=0.01, batch_size=500, activation=<function elu at 0x1099692f0>, total=  29.2s\n",
      "[CV] n_neurons=50, learning_rate=0.1, batch_size=10, activation=<function relu at 0x10998d488> \n",
      "0\tValidation loss: 1.637583\tBest loss: 1.637583\tAccuracy: 19.27%\n",
      "1\tValidation loss: 1.621896\tBest loss: 1.621896\tAccuracy: 19.27%\n",
      "2\tValidation loss: 1.619831\tBest loss: 1.619831\tAccuracy: 19.27%\n",
      "3\tValidation loss: 1.616520\tBest loss: 1.616520\tAccuracy: 19.27%\n",
      "4\tValidation loss: 1.654958\tBest loss: 1.616520\tAccuracy: 22.01%\n",
      "5\tValidation loss: 1.621479\tBest loss: 1.616520\tAccuracy: 22.01%\n",
      "6\tValidation loss: 1.632693\tBest loss: 1.616520\tAccuracy: 19.27%\n",
      "7\tValidation loss: 1.614858\tBest loss: 1.614858\tAccuracy: 19.27%\n",
      "8\tValidation loss: 1.642606\tBest loss: 1.614858\tAccuracy: 19.27%\n",
      "9\tValidation loss: 1.639819\tBest loss: 1.614858\tAccuracy: 19.27%\n",
      "10\tValidation loss: 1.615375\tBest loss: 1.614858\tAccuracy: 22.01%\n",
      "11\tValidation loss: 1.630571\tBest loss: 1.614858\tAccuracy: 22.01%\n",
      "12\tValidation loss: 1.636737\tBest loss: 1.614858\tAccuracy: 19.08%\n",
      "13\tValidation loss: 1.613103\tBest loss: 1.613103\tAccuracy: 19.27%\n",
      "14\tValidation loss: 1.629263\tBest loss: 1.613103\tAccuracy: 19.08%\n",
      "15\tValidation loss: 1.617149\tBest loss: 1.613103\tAccuracy: 22.01%\n",
      "16\tValidation loss: 1.626923\tBest loss: 1.613103\tAccuracy: 18.73%\n",
      "17\tValidation loss: 1.608595\tBest loss: 1.608595\tAccuracy: 22.01%\n",
      "18\tValidation loss: 1.624737\tBest loss: 1.608595\tAccuracy: 19.27%\n",
      "19\tValidation loss: 1.624035\tBest loss: 1.608595\tAccuracy: 20.91%\n",
      "20\tValidation loss: 1.615449\tBest loss: 1.608595\tAccuracy: 19.27%\n",
      "21\tValidation loss: 1.629650\tBest loss: 1.608595\tAccuracy: 19.27%\n",
      "22\tValidation loss: 1.619098\tBest loss: 1.608595\tAccuracy: 19.27%\n",
      "23\tValidation loss: 1.621080\tBest loss: 1.608595\tAccuracy: 22.01%\n",
      "24\tValidation loss: 1.633989\tBest loss: 1.608595\tAccuracy: 22.01%\n",
      "25\tValidation loss: 1.647182\tBest loss: 1.608595\tAccuracy: 22.01%\n",
      "26\tValidation loss: 1.614127\tBest loss: 1.608595\tAccuracy: 19.08%\n",
      "27\tValidation loss: 1.638548\tBest loss: 1.608595\tAccuracy: 19.27%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\tValidation loss: 1.656264\tBest loss: 1.608595\tAccuracy: 22.01%\n",
      "29\tValidation loss: 1.617747\tBest loss: 1.608595\tAccuracy: 18.73%\n",
      "30\tValidation loss: 1.641874\tBest loss: 1.608595\tAccuracy: 19.27%\n",
      "31\tValidation loss: 1.631482\tBest loss: 1.608595\tAccuracy: 18.73%\n",
      "32\tValidation loss: 1.641183\tBest loss: 1.608595\tAccuracy: 18.73%\n",
      "33\tValidation loss: 1.647446\tBest loss: 1.608595\tAccuracy: 19.08%\n",
      "34\tValidation loss: 1.610284\tBest loss: 1.608595\tAccuracy: 22.01%\n",
      "35\tValidation loss: 1.624692\tBest loss: 1.608595\tAccuracy: 19.08%\n",
      "36\tValidation loss: 1.630852\tBest loss: 1.608595\tAccuracy: 18.73%\n",
      "37\tValidation loss: 1.632281\tBest loss: 1.608595\tAccuracy: 18.73%\n",
      "38\tValidation loss: 1.631021\tBest loss: 1.608595\tAccuracy: 22.01%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=50, learning_rate=0.1, batch_size=10, activation=<function relu at 0x10998d488>, total= 2.3min\n",
      "[CV] n_neurons=50, learning_rate=0.1, batch_size=10, activation=<function relu at 0x10998d488> \n",
      "0\tValidation loss: 1.631920\tBest loss: 1.631920\tAccuracy: 22.01%\n",
      "1\tValidation loss: 1.644836\tBest loss: 1.631920\tAccuracy: 19.08%\n",
      "2\tValidation loss: 1.611654\tBest loss: 1.611654\tAccuracy: 22.01%\n",
      "3\tValidation loss: 1.614178\tBest loss: 1.611654\tAccuracy: 22.01%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-ce0a02b5dd9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mrnd_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDNNClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distribs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"X_valid\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_valid1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"y_valid\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_valid1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_epochs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mrnd_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    636\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    637\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 638\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-2d1eb2eecd06>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, n_epochs, X_valid, y_valid)\u001b[0m\n\u001b[1;32m    132\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mextra_update_ops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_update_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def leaky_relu(alpha = 0.01):\n",
    "    def parametrized_leaky_relu(z, name = None):\n",
    "        return tf.maximum(alpha*z, z, name = name)\n",
    "    return parametrized_leaky_relu\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_neurons\": [10, 30, 50, 70, 90, 100, 120, 140, 160],\n",
    "    \"batch_size\": [10, 50, 100, 500],\n",
    "    \"learning_rate\": [0.01, 0.02, 0.05, 0.1],\n",
    "    \"activation\": [tf.nn.relu, tf.nn.elu, leaky_relu(alpha = 0.01), leaky_relu(alpha = 0.1)]\n",
    "}\n",
    "\n",
    "rnd_search = RandomizedSearchCV(DNNClassifier(random_state = 42), param_distribs, n_iter = 50, fit_params = {\"X_valid\": X_valid1, \"y_valid\": y_valid1, \"n_epochs\": 1000}, random_state = 42, verbose = 2)\n",
    "rnd_search.fit(X_train1, y_train1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
